{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYZING THE INDIAN START-UP ECOSYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Description\n",
    "This project involves analyzing the funding received by startups in India from 2018 to 2021.\n",
    "Leveraging the CRISP-DM (Cross-Industry Standard Process for Data Mining) methodology, We will identify key trends, sectoral and geographical distribution of funding,investor dynamics, and existing challenges within the ecosystem. The ultimate goal is to  proposing the best course of action to investors and foster a more robust and sustainable startup environment in India.\n",
    "The datasets provided contain details of the startups,geographical location, the funding amounts recieved,investor information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objectives\n",
    "1. Identify key investment trends in the Indian startup ecosystem from 2018 to 2021\n",
    "2. Explore the distribution of startup funding across different sectors and regions in India.\n",
    "3. Determine high-growth sectors that attract significant funding.\n",
    "4. Analyze investor activity and preferences within the ecosystem.\n",
    "5. Understand the characteristics of startups that receive substantial funding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis\n",
    "Hypothesis  (Alternative Hypothesis): There is significant increase  in the amount of funding received by Indian start-ups from 2018 to 2021.\n",
    "Null Hypothesis: There is no significant increase in the amount of funding received by Indian startups from 2018 to 2021.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytical Questions\n",
    "1.\tWhat are the trends in the total amount of funding received by Indian startups from 2018 to 2021?\n",
    "2.\tWhich sectors have attracted the most investment during each year, and how have these trends evolved over the four years?\n",
    "3.\tWho are the highest investors, Total Fund invested and sector? \n",
    "4.\tAt which stage are Indian-Start-ups funded the most?\n",
    "5. How is startup funding distributed across different sectors and regions. Highest and lowest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Understanding\n",
    "##### Loading datasets from different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary libraries\n",
    "import pyodbc     \n",
    "from dotenv import dotenv_values    #import the dotenv_values function from the dotenv package\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Round/Series</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Location</th>\n",
       "      <th>About Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Agriculture, Farming</td>\n",
       "      <td>Seed</td>\n",
       "      <td>₹40,000,000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Credit, Financial Services, Lending, Marketplace</td>\n",
       "      <td>Series A</td>\n",
       "      <td>₹65,000,000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company Name                                           Industry  \\\n",
       "0  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
       "1  Happy Cow Dairy                               Agriculture, Farming   \n",
       "2       MyLoanCare   Credit, Financial Services, Lending, Marketplace   \n",
       "\n",
       "  Round/Series       Amount                     Location  \\\n",
       "0         Seed       250000  Bangalore, Karnataka, India   \n",
       "1         Seed  ₹40,000,000   Mumbai, Maharashtra, India   \n",
       "2     Series A  ₹65,000,000      Gurgaon, Haryana, India   \n",
       "\n",
       "                                       About Company  \n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...  \n",
       "1  A startup which aggregates milk from dairy far...  \n",
       "2          Leading Online Loans Marketplace in India  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load 2018 data \n",
    "data_18 = pd.read_csv('startup_funding2018.csv')\n",
    "\n",
    "#View data\n",
    "data_18.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- some details in the amount column were given in INR(rupees) and need to be converted to dolar.The commas in the column also need to be stripped.\n",
    "- location column nee to be cleaned and the commas stripped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company/Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What it does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount($)</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bombay Shaving</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ecommerce</td>\n",
       "      <td>Provides a range of male grooming products</td>\n",
       "      <td>Shantanu Deshpande</td>\n",
       "      <td>Sixth Sense Ventures</td>\n",
       "      <td>$6,300,000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ruangguru</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>A learning platform that provides topic-based ...</td>\n",
       "      <td>Adamas Belva Syah Devara, Iman Usman.</td>\n",
       "      <td>General Atlantic</td>\n",
       "      <td>$150,000,000</td>\n",
       "      <td>Series C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eduisfun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Edtech</td>\n",
       "      <td>It aims to make learning fun via games.</td>\n",
       "      <td>Jatin Solanki</td>\n",
       "      <td>Deepak Parekh, Amitabh Bachchan, Piyush Pandey</td>\n",
       "      <td>$28,000,000</td>\n",
       "      <td>Fresh funding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company/Brand  Founded HeadQuarter     Sector  \\\n",
       "0  Bombay Shaving      NaN         NaN  Ecommerce   \n",
       "1       Ruangguru   2014.0      Mumbai     Edtech   \n",
       "2        Eduisfun      NaN      Mumbai     Edtech   \n",
       "\n",
       "                                        What it does  \\\n",
       "0         Provides a range of male grooming products   \n",
       "1  A learning platform that provides topic-based ...   \n",
       "2            It aims to make learning fun via games.   \n",
       "\n",
       "                                Founders  \\\n",
       "0                     Shantanu Deshpande   \n",
       "1  Adamas Belva Syah Devara, Iman Usman.   \n",
       "2                          Jatin Solanki   \n",
       "\n",
       "                                         Investor      Amount($)  \\\n",
       "0                            Sixth Sense Ventures    $6,300,000    \n",
       "1                                General Atlantic  $150,000,000    \n",
       "2  Deepak Parekh, Amitabh Bachchan, Piyush Pandey   $28,000,000    \n",
       "\n",
       "           Stage  \n",
       "0            NaN  \n",
       "1       Series C  \n",
       "2  Fresh funding  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load 2019 data \n",
    "data_19 = pd.read_csv('startup_funding2019.csv',encoding = \"ISO-8859-1\")\n",
    "\n",
    "#View data\n",
    "data_19.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the amount column ,location need to be cleaned and the commas stripped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file into a dictionary to access 2020 and 2021 datasets from database\n",
    "environment_variables = dotenv_values('.env')\n",
    "\n",
    "# Get the values for the credentials you set in the '.env' file\n",
    "server = environment_variables.get(\"server\")\n",
    "database = environment_variables.get(\"database\")\n",
    "login = environment_variables.get(\"login\")\n",
    "password = environment_variables.get(\"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection string\n",
    "connection_string = f\"DRIVER={{SQL Server}};SERVER={server};DATABASE={database};UID={login};PWD={password};MARS_Connection=yes;MinProtocolVersion=TLSv1.2;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the connect method of the pyodbc library and pass in the connection string.\n",
    "connection = pyodbc.connect(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TABLE_CATALOG</th>\n",
       "      <th>TABLE_SCHEMA</th>\n",
       "      <th>TABLE_NAME</th>\n",
       "      <th>TABLE_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dapDB</td>\n",
       "      <td>dbo</td>\n",
       "      <td>LP1_startup_funding2021</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dapDB</td>\n",
       "      <td>dbo</td>\n",
       "      <td>LP1_startup_funding2020</td>\n",
       "      <td>BASE TABLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TABLE_CATALOG TABLE_SCHEMA               TABLE_NAME  TABLE_TYPE\n",
       "0         dapDB          dbo  LP1_startup_funding2021  BASE TABLE\n",
       "1         dapDB          dbo  LP1_startup_funding2020  BASE TABLE"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write an sql query to get data\n",
    "\n",
    "query = '''SELECT *\n",
    "           FROM INFORMATION_SCHEMA.TABLES\n",
    "           WHERE TABLE_TYPE = 'BASE TABLE'\n",
    "        '''\n",
    "data = pd.read_sql(query, connection)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aqgromalin</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>AgriTech</td>\n",
       "      <td>Cultivating Ideas for Profit</td>\n",
       "      <td>Prasanna Manogaran, Bharani C L</td>\n",
       "      <td>Angel investors</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krayonnz</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>An academy-guardian-scholar centric ecosystem ...</td>\n",
       "      <td>Saurabh Dixit, Gurudutt Upadhyay</td>\n",
       "      <td>GSF Accelerator</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PadCare Labs</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Hygiene management</td>\n",
       "      <td>Converting bio-hazardous waste to harmless waste</td>\n",
       "      <td>Ajinkya Dhariya</td>\n",
       "      <td>Venture Center</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pre-seed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCOME</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Escrow</td>\n",
       "      <td>Escrow-as-a-service platform</td>\n",
       "      <td>Ritesh Tiwari</td>\n",
       "      <td>Venture Catalysts, PointOne Capital</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company_Brand  Founded HeadQuarter              Sector  \\\n",
       "0    Aqgromalin   2019.0     Chennai            AgriTech   \n",
       "1      Krayonnz   2019.0   Bangalore              EdTech   \n",
       "2  PadCare Labs   2018.0        Pune  Hygiene management   \n",
       "3         NCOME   2020.0   New Delhi              Escrow   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0                       Cultivating Ideas for Profit   \n",
       "1  An academy-guardian-scholar centric ecosystem ...   \n",
       "2   Converting bio-hazardous waste to harmless waste   \n",
       "3                       Escrow-as-a-service platform   \n",
       "\n",
       "                           Founders                             Investor  \\\n",
       "0   Prasanna Manogaran, Bharani C L                      Angel investors   \n",
       "1  Saurabh Dixit, Gurudutt Upadhyay                      GSF Accelerator   \n",
       "2                   Ajinkya Dhariya                       Venture Center   \n",
       "3                     Ritesh Tiwari  Venture Catalysts, PointOne Capital   \n",
       "\n",
       "     Amount     Stage column10  \n",
       "0  200000.0      None     None  \n",
       "1  100000.0  Pre-seed     None  \n",
       "2       NaN  Pre-seed     None  \n",
       "3  400000.0      None     None  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write an sql query to extract 2020 details from the data\n",
    "query = '''SELECT *\n",
    "           FROM LP1_startup_funding2020\n",
    "        '''\n",
    "data_20 = pd.read_sql(query, connection)\n",
    "data_20.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Brand</th>\n",
       "      <th>Founded</th>\n",
       "      <th>HeadQuarter</th>\n",
       "      <th>Sector</th>\n",
       "      <th>What_it_does</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unbox Robotics</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>AI startup</td>\n",
       "      <td>Unbox Robotics builds on-demand AI-driven ware...</td>\n",
       "      <td>Pramod Ghadge, Shahid Memon</td>\n",
       "      <td>BEENEXT, Entrepreneur First</td>\n",
       "      <td>$1,200,000</td>\n",
       "      <td>Pre-series A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upGrad</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>UpGrad is an online higher education platform.</td>\n",
       "      <td>Mayank Kumar, Phalgun Kompalli, Ravijot Chugh,...</td>\n",
       "      <td>Unilazer Ventures, IIFL Asset Management</td>\n",
       "      <td>$120,000,000</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead School</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>LEAD School offers technology based school tra...</td>\n",
       "      <td>Smita Deorah, Sumeet Mehta</td>\n",
       "      <td>GSV Ventures, Westbridge Capital</td>\n",
       "      <td>$30,000,000</td>\n",
       "      <td>Series D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bizongo</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>B2B E-commerce</td>\n",
       "      <td>Bizongo is a business-to-business online marke...</td>\n",
       "      <td>Aniket Deb, Ankit Tomar, Sachin Agrawal</td>\n",
       "      <td>CDC Group, IDG Capital</td>\n",
       "      <td>$51,000,000</td>\n",
       "      <td>Series C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FypMoney</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>FypMoney is Digital NEO Bank for Teenagers, em...</td>\n",
       "      <td>Kapil Banwari</td>\n",
       "      <td>Liberatha Kallat, Mukesh Yadav, Dinesh Nagpal</td>\n",
       "      <td>$2,000,000</td>\n",
       "      <td>Seed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company_Brand  Founded HeadQuarter          Sector  \\\n",
       "0  Unbox Robotics   2019.0   Bangalore      AI startup   \n",
       "1          upGrad   2015.0      Mumbai          EdTech   \n",
       "2     Lead School   2012.0      Mumbai          EdTech   \n",
       "3         Bizongo   2015.0      Mumbai  B2B E-commerce   \n",
       "4        FypMoney   2021.0    Gurugram         FinTech   \n",
       "\n",
       "                                        What_it_does  \\\n",
       "0  Unbox Robotics builds on-demand AI-driven ware...   \n",
       "1     UpGrad is an online higher education platform.   \n",
       "2  LEAD School offers technology based school tra...   \n",
       "3  Bizongo is a business-to-business online marke...   \n",
       "4  FypMoney is Digital NEO Bank for Teenagers, em...   \n",
       "\n",
       "                                            Founders  \\\n",
       "0                        Pramod Ghadge, Shahid Memon   \n",
       "1  Mayank Kumar, Phalgun Kompalli, Ravijot Chugh,...   \n",
       "2                         Smita Deorah, Sumeet Mehta   \n",
       "3            Aniket Deb, Ankit Tomar, Sachin Agrawal   \n",
       "4                                      Kapil Banwari   \n",
       "\n",
       "                                        Investor        Amount         Stage  \n",
       "0                    BEENEXT, Entrepreneur First    $1,200,000  Pre-series A  \n",
       "1       Unilazer Ventures, IIFL Asset Management  $120,000,000          None  \n",
       "2               GSV Ventures, Westbridge Capital   $30,000,000      Series D  \n",
       "3                         CDC Group, IDG Capital   $51,000,000      Series C  \n",
       "4  Liberatha Kallat, Mukesh Yadav, Dinesh Nagpal    $2,000,000          Seed  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#write an sql query to extract 2021 details from the database\n",
    "query = '''SELECT *\n",
    "\n",
    "           FROM LP1_startup_funding2021\n",
    "        '''\n",
    "data_21 = pd.read_sql(query, connection)\n",
    "data_21.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-amount column needs to be cleaned, dollar sign removed and commas removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "column names and description:\n",
    "\n",
    "Company/Brand: Name of the company/start-up\n",
    "\n",
    "Founded: Year start-up was founded\n",
    "\n",
    "Sector: Sector of service\n",
    "\n",
    "What it does: Description about Company\n",
    "\n",
    "Founders: Founders of the Company\n",
    "\n",
    "Investor: Investors\n",
    "\n",
    "Amount($): Raised fund from grants\n",
    "\n",
    "Stage: funding stage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data description/EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((526, 6), (89, 9), (1055, 10), (1209, 9))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a look at the shape of the dataframes\n",
    "data_18.shape , data_19.shape , data_20.shape , data_21.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 526 entries, 0 to 525\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Company Name   526 non-null    object\n",
      " 1   Industry       526 non-null    object\n",
      " 2   Round/Series   526 non-null    object\n",
      " 3   Amount         526 non-null    object\n",
      " 4   Location       526 non-null    object\n",
      " 5   About Company  526 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 24.8+ KB\n",
      "None \n",
      "============= Null Values =============================\n",
      "Company Name     0\n",
      "Industry         0\n",
      "Round/Series     0\n",
      "Amount           0\n",
      "Location         0\n",
      "About Company    0\n",
      "dtype: int64 \n",
      "============= Duplicate rows =============================\n",
      "        Company Name                                           Industry  \\\n",
      "348  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
      "\n",
      "    Round/Series  Amount                     Location  \\\n",
      "348         Seed  250000  Bangalore, Karnataka, India   \n",
      "\n",
      "                                         About Company  \n",
      "348  TheCollegeFever is a hub for fun, fiesta and f...  \n"
     ]
    }
   ],
   "source": [
    "# a quick overview of the datatypes for 2018 dataset\n",
    "print(data_18.info(), \"\\n============= Null Values =============================\")\n",
    "\n",
    "#check for null values\n",
    "print(data_18.isna().sum(), \"\\n============= Duplicate rows =============================\")\n",
    "\n",
    "#check for duplicates\n",
    "print(data_18[data_18.duplicated()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 89 entries, 0 to 88\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company/Brand  89 non-null     object \n",
      " 1   Founded        60 non-null     float64\n",
      " 2   HeadQuarter    70 non-null     object \n",
      " 3   Sector         84 non-null     object \n",
      " 4   What it does   89 non-null     object \n",
      " 5   Founders       86 non-null     object \n",
      " 6   Investor       89 non-null     object \n",
      " 7   Amount($)      89 non-null     object \n",
      " 8   Stage          43 non-null     object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 6.4+ KB\n",
      "None \n",
      "============= Null Values =============================\n",
      "Company/Brand     0\n",
      "Founded          29\n",
      "HeadQuarter      19\n",
      "Sector            5\n",
      "What it does      0\n",
      "Founders          3\n",
      "Investor          0\n",
      "Amount($)         0\n",
      "Stage            46\n",
      "dtype: int64 \n",
      "============= Duplicate rows =============================\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#check the datatypes in 2019 dataset\n",
    "print(data_19.info(), \"\\n============= Null Values =============================\")\n",
    "\n",
    "#check for null values\n",
    "print(data_19.isna().sum(), \"\\n============= Duplicate rows =============================\")\n",
    "#check for duplicates\n",
    "print(data_19.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1055 entries, 0 to 1054\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1055 non-null   object \n",
      " 1   Founded        842 non-null    float64\n",
      " 2   HeadQuarter    961 non-null    object \n",
      " 3   Sector         1042 non-null   object \n",
      " 4   What_it_does   1055 non-null   object \n",
      " 5   Founders       1043 non-null   object \n",
      " 6   Investor       1017 non-null   object \n",
      " 7   Amount         801 non-null    float64\n",
      " 8   Stage          591 non-null    object \n",
      " 9   column10       2 non-null      object \n",
      "dtypes: float64(2), object(8)\n",
      "memory usage: 82.5+ KB\n",
      "None \n",
      "============= Null Values =============================\n",
      "Company_Brand       0\n",
      "Founded           213\n",
      "HeadQuarter        94\n",
      "Sector             13\n",
      "What_it_does        0\n",
      "Founders           12\n",
      "Investor           38\n",
      "Amount            254\n",
      "Stage             464\n",
      "column10         1053\n",
      "dtype: int64 \n",
      "============= Duplicate rows =============================\n",
      " total number of duplicates for 2020 is 3\n"
     ]
    }
   ],
   "source": [
    "#overview of 2020 datatypes\n",
    "print(data_20.info(), \"\\n============= Null Values =============================\")\n",
    "\n",
    "#check for null values\n",
    "print(data_20.isna().sum(), \"\\n============= Duplicate rows =============================\")\n",
    "\n",
    "#check for duplicates\n",
    "print(f\" total number of duplicates for 2020 is {data_20.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1209 entries, 0 to 1208\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Company_Brand  1209 non-null   object \n",
      " 1   Founded        1208 non-null   float64\n",
      " 2   HeadQuarter    1208 non-null   object \n",
      " 3   Sector         1209 non-null   object \n",
      " 4   What_it_does   1209 non-null   object \n",
      " 5   Founders       1205 non-null   object \n",
      " 6   Investor       1147 non-null   object \n",
      " 7   Amount         1206 non-null   object \n",
      " 8   Stage          781 non-null    object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 85.1+ KB\n",
      "None \n",
      "============= Null Values =============================\n",
      "Company_Brand      0\n",
      "Founded            1\n",
      "HeadQuarter        1\n",
      "Sector             0\n",
      "What_it_does       0\n",
      "Founders           4\n",
      "Investor          62\n",
      "Amount             3\n",
      "Stage            428\n",
      "dtype: int64 \n",
      "============= Duplicate rows =============================\n",
      "total number of duplicate rows for 2021 dataset is 19\n"
     ]
    }
   ],
   "source": [
    "#Overview of 2021 datatype\n",
    "print(data_21.info(), \"\\n============= Null Values =============================\")\n",
    "\n",
    "#check for null values\n",
    "print(data_21.isna().sum(), \"\\n============= Duplicate rows =============================\")\n",
    "\n",
    "#check for duplicates\n",
    "print(f\"total number of duplicate rows for 2021 dataset is {data_21.duplicated().sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "1. 2020 and 2021 datasets have different column names in comparison to 2018 and 2019 datasets.This has to be renamed for uniformity before merging the datasets.\n",
    "2. The 2018 dataset exhibits some missing columns, contributing to an incomplete representation of the data.\n",
    "3. The 2020 dataset contains an additional column that appears to be extraneous and does not serve a meaningful purpose in our analysis and will be removed\n",
    "4. 2018 dataset has 1 duplicate row, 2020 has 3 duplicate rows and 2021 has 19 duplicate rows.\n",
    "5. We can also see the total number of missing values in each column of our dataset, These will be handled in the data cleaning phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "we have a total of 4 datasets from different sources and need to be merged before we can perform data cleaning and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column for the year funding was recieved for each dataframe before merging.\n",
    "data_21['year_funded']= '2021'\n",
    "data_20['year_funded']= '2020'\n",
    "data_19['year_funded']= '2019'\n",
    "data_18['year_funded']= '2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>funding_stage</th>\n",
       "      <th>Amount_in_usd</th>\n",
       "      <th>Location</th>\n",
       "      <th>about_company</th>\n",
       "      <th>year_funded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Agriculture, Farming</td>\n",
       "      <td>Seed</td>\n",
       "      <td>₹40,000,000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Credit, Financial Services, Lending, Marketplace</td>\n",
       "      <td>Series A</td>\n",
       "      <td>₹65,000,000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PayMe India</td>\n",
       "      <td>Financial Services, FinTech</td>\n",
       "      <td>Angel</td>\n",
       "      <td>2000000</td>\n",
       "      <td>Noida, Uttar Pradesh, India</td>\n",
       "      <td>PayMe India is an innovative FinTech organizat...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eunimart</td>\n",
       "      <td>E-Commerce Platforms, Retail, SaaS</td>\n",
       "      <td>Seed</td>\n",
       "      <td>—</td>\n",
       "      <td>Hyderabad, Andhra Pradesh, India</td>\n",
       "      <td>Eunimart is a one stop solution for merchants ...</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company_name                                           industry  \\\n",
       "0  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
       "1  Happy Cow Dairy                               Agriculture, Farming   \n",
       "2       MyLoanCare   Credit, Financial Services, Lending, Marketplace   \n",
       "3      PayMe India                        Financial Services, FinTech   \n",
       "4         Eunimart                 E-Commerce Platforms, Retail, SaaS   \n",
       "\n",
       "  funding_stage Amount_in_usd                          Location  \\\n",
       "0          Seed        250000       Bangalore, Karnataka, India   \n",
       "1          Seed   ₹40,000,000        Mumbai, Maharashtra, India   \n",
       "2      Series A   ₹65,000,000           Gurgaon, Haryana, India   \n",
       "3         Angel       2000000       Noida, Uttar Pradesh, India   \n",
       "4          Seed             —  Hyderabad, Andhra Pradesh, India   \n",
       "\n",
       "                                       about_company year_funded  \n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...        2018  \n",
       "1  A startup which aggregates milk from dairy far...        2018  \n",
       "2          Leading Online Loans Marketplace in India        2018  \n",
       "3  PayMe India is an innovative FinTech organizat...        2018  \n",
       "4  Eunimart is a one stop solution for merchants ...        2018  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rename column names for each dataframe for uniformity before merging\n",
    "\n",
    "data_18.rename(columns = {'Company Name':'company_name','Round/Series':'funding_stage','About Company': 'about_company','Industry':'industry','Amount':'Amount_in_usd'},inplace = True)\n",
    "data_19.rename(columns = {'Company/Brand':'company_name','HeadQuarter':'Location','Sector':'industry','What it does' :'about_company','Amount($)':'Amount_in_usd','Stage': 'funding_stage'},inplace = True)\n",
    "data_20.rename(columns = {'Company_Brand':'company_name','HeadQuarter':'Location','Sector':'industry','What_it_does' :'about_company','Amount':'Amount_in_usd','Stage': 'funding_stage'},inplace = True)\n",
    "data_21.rename(columns = {'Company_Brand':'company_name','HeadQuarter':'Location','Sector':'industry','What_it_does' :'about_company','Amount':'Amount_in_usd','Stage': 'funding_stage'},inplace = True)\n",
    "\n",
    "#preview the data\n",
    "data_18.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>funding_stage</th>\n",
       "      <th>Amount_in_usd</th>\n",
       "      <th>Location</th>\n",
       "      <th>about_company</th>\n",
       "      <th>year_funded</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>Gigforce</td>\n",
       "      <td>Staffing &amp; Recruiting</td>\n",
       "      <td>Pre-series A</td>\n",
       "      <td>$3000000</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>A gig/on-demand staffing company.</td>\n",
       "      <td>2021</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Chirag Mittal, Anirudh Syal</td>\n",
       "      <td>Endiya Partners</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>Vahdam</td>\n",
       "      <td>Food &amp; Beverages</td>\n",
       "      <td>Series D</td>\n",
       "      <td>$20000000</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>VAHDAM is among the world’s first vertically i...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Bala Sarda</td>\n",
       "      <td>IIFL AMC</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>Leap Finance</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Series C</td>\n",
       "      <td>$55000000</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>International education loans for high potenti...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Arnav Kumar, Vaibhav Singh</td>\n",
       "      <td>Owl Ventures</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>CollegeDekho</td>\n",
       "      <td>EdTech</td>\n",
       "      <td>Series B</td>\n",
       "      <td>$26000000</td>\n",
       "      <td>Gurugram</td>\n",
       "      <td>Collegedekho.com is Student’s Partner, Friend ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>Ruchir Arora</td>\n",
       "      <td>Winter Capital, ETS, Man Capital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>WeRize</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Series A</td>\n",
       "      <td>$8000000</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>India’s first socially distributed full stack ...</td>\n",
       "      <td>2021</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>Vishal Chopra, Himanshu Gupta</td>\n",
       "      <td>3one4 Capital, Kalaari Capital</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      company_name               industry funding_stage Amount_in_usd  \\\n",
       "1204      Gigforce  Staffing & Recruiting  Pre-series A      $3000000   \n",
       "1205        Vahdam       Food & Beverages      Series D     $20000000   \n",
       "1206  Leap Finance     Financial Services      Series C     $55000000   \n",
       "1207  CollegeDekho                 EdTech      Series B     $26000000   \n",
       "1208        WeRize     Financial Services      Series A      $8000000   \n",
       "\n",
       "       Location                                      about_company  \\\n",
       "1204   Gurugram                  A gig/on-demand staffing company.   \n",
       "1205  New Delhi  VAHDAM is among the world’s first vertically i...   \n",
       "1206  Bangalore  International education loans for high potenti...   \n",
       "1207   Gurugram  Collegedekho.com is Student’s Partner, Friend ...   \n",
       "1208  Bangalore  India’s first socially distributed full stack ...   \n",
       "\n",
       "     year_funded  Founded                       Founders  \\\n",
       "1204        2021   2019.0    Chirag Mittal, Anirudh Syal   \n",
       "1205        2021   2015.0                     Bala Sarda   \n",
       "1206        2021   2019.0     Arnav Kumar, Vaibhav Singh   \n",
       "1207        2021   2015.0                   Ruchir Arora   \n",
       "1208        2021   2019.0  Vishal Chopra, Himanshu Gupta   \n",
       "\n",
       "                              Investor column10  \n",
       "1204                   Endiya Partners      NaN  \n",
       "1205                          IIFL AMC      NaN  \n",
       "1206                      Owl Ventures      NaN  \n",
       "1207  Winter Capital, ETS, Man Capital      NaN  \n",
       "1208    3one4 Capital, Kalaari Capital      NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge all dataframes\n",
    "\n",
    "merged_df = pd.concat([data_18,data_19,data_20,data_21], axis = 0)\n",
    "\n",
    "#view the merged dataframe\n",
    "merged_df.tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2879 entries, 0 to 1208\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_name   2879 non-null   object \n",
      " 1   industry       2861 non-null   object \n",
      " 2   funding_stage  1941 non-null   object \n",
      " 3   Amount_in_usd  2622 non-null   object \n",
      " 4   Location       2765 non-null   object \n",
      " 5   about_company  2879 non-null   object \n",
      " 6   year_funded    2879 non-null   object \n",
      " 7   Founded        2110 non-null   float64\n",
      " 8   Founders       2334 non-null   object \n",
      " 9   Investor       2253 non-null   object \n",
      " 10  column10       2 non-null      object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 269.9+ KB\n",
      "============Number of unique values===============\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "company_name     2214\n",
       "industry          873\n",
       "funding_stage      75\n",
       "Amount_in_usd     803\n",
       "Location          172\n",
       "about_company    2691\n",
       "year_funded         4\n",
       "Founded            34\n",
       "Founders         1980\n",
       "Investor         1777\n",
       "column10            2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the datatype\n",
    "merged_df.info()\n",
    "print(f'============Number of unique values===============')\n",
    "merged_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2879 entries, 0 to 1208\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   company_name   2879 non-null   object \n",
      " 1   industry       2861 non-null   object \n",
      " 2   funding_stage  1941 non-null   object \n",
      " 3   Amount_in_usd  2622 non-null   object \n",
      " 4   Location       2765 non-null   object \n",
      " 5   about_company  2879 non-null   object \n",
      " 6   year_funded    2879 non-null   int32  \n",
      " 7   Founded        2110 non-null   float64\n",
      " 8   Founders       2334 non-null   object \n",
      " 9   Investor       2253 non-null   object \n",
      " 10  column10       2 non-null      object \n",
      "dtypes: float64(1), int32(1), object(9)\n",
      "memory usage: 258.7+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#convert the year column to date format\n",
    "merged_df['year_funded'] = pd.to_datetime(merged_df['year_funded'],format='%Y').dt.year\n",
    "\n",
    "#convert the Founded column to date format\n",
    "merged_df['Founded'] = pd.to_datetime(merged_df['Founded'],format='%Y').dt.year\n",
    "\n",
    "#view the result\n",
    "merged_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>funding_stage</th>\n",
       "      <th>Amount_in_usd</th>\n",
       "      <th>Location</th>\n",
       "      <th>about_company</th>\n",
       "      <th>year_funded</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>column10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2879</td>\n",
       "      <td>2861</td>\n",
       "      <td>1941</td>\n",
       "      <td>2622</td>\n",
       "      <td>2765</td>\n",
       "      <td>2879</td>\n",
       "      <td>2879.000000</td>\n",
       "      <td>2110.000000</td>\n",
       "      <td>2334</td>\n",
       "      <td>2253</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2214</td>\n",
       "      <td>873</td>\n",
       "      <td>75</td>\n",
       "      <td>803</td>\n",
       "      <td>172</td>\n",
       "      <td>2691</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "      <td>1777</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>BharatPe</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Seed</td>\n",
       "      <td>—</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>BYJU'S is an educational technology company th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Byju Raveendran</td>\n",
       "      <td>Inflection Point Ventures</td>\n",
       "      <td>Pre-Seed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "      <td>606</td>\n",
       "      <td>148</td>\n",
       "      <td>764</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.023619</td>\n",
       "      <td>2016.079621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.086974</td>\n",
       "      <td>4.368006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       company_name industry funding_stage Amount_in_usd   Location  \\\n",
       "count          2879     2861          1941          2622       2765   \n",
       "unique         2214      873            75           803        172   \n",
       "top        BharatPe  FinTech          Seed             —  Bangalore   \n",
       "freq             10      173           606           148        764   \n",
       "mean            NaN      NaN           NaN           NaN        NaN   \n",
       "std             NaN      NaN           NaN           NaN        NaN   \n",
       "min             NaN      NaN           NaN           NaN        NaN   \n",
       "25%             NaN      NaN           NaN           NaN        NaN   \n",
       "50%             NaN      NaN           NaN           NaN        NaN   \n",
       "75%             NaN      NaN           NaN           NaN        NaN   \n",
       "max             NaN      NaN           NaN           NaN        NaN   \n",
       "\n",
       "                                            about_company  year_funded  \\\n",
       "count                                                2879  2879.000000   \n",
       "unique                                               2691          NaN   \n",
       "top     BYJU'S is an educational technology company th...          NaN   \n",
       "freq                                                    5          NaN   \n",
       "mean                                                  NaN  2020.023619   \n",
       "std                                                   NaN     1.086974   \n",
       "min                                                   NaN  2018.000000   \n",
       "25%                                                   NaN  2020.000000   \n",
       "50%                                                   NaN  2020.000000   \n",
       "75%                                                   NaN  2021.000000   \n",
       "max                                                   NaN  2021.000000   \n",
       "\n",
       "            Founded         Founders                   Investor  column10  \n",
       "count   2110.000000             2334                       2253         2  \n",
       "unique          NaN             1980                       1777         2  \n",
       "top             NaN  Byju Raveendran  Inflection Point Ventures  Pre-Seed  \n",
       "freq            NaN                7                         36         1  \n",
       "mean    2016.079621              NaN                        NaN       NaN  \n",
       "std        4.368006              NaN                        NaN       NaN  \n",
       "min     1963.000000              NaN                        NaN       NaN  \n",
       "25%     2015.000000              NaN                        NaN       NaN  \n",
       "50%     2017.000000              NaN                        NaN       NaN  \n",
       "75%     2019.000000              NaN                        NaN       NaN  \n",
       "max     2021.000000              NaN                        NaN       NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The descriptive statistics above has a lot of NaN and duplicate values due to the nature of our dataset which has to be cleaned before we can perform the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop redundant column 10\n",
    "merged_df.drop(columns='column10',axis=1,inplace=True)\n",
    "\n",
    "#check for duplicates\n",
    "merged_df[merged_df.duplicated()]\n",
    "\n",
    "#drop the duplicates\n",
    "merged_df.drop_duplicates(keep='first',inplace =True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.duplicated().sum()\n",
    "\n",
    "#reset the index\n",
    "merged_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>funding_stage</th>\n",
       "      <th>Amount_in_usd</th>\n",
       "      <th>Location</th>\n",
       "      <th>about_company</th>\n",
       "      <th>year_funded</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TheCollegeFever</td>\n",
       "      <td>Brand Marketing, Event Promotion, Marketing, S...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>250000</td>\n",
       "      <td>Bangalore, Karnataka, India</td>\n",
       "      <td>TheCollegeFever is a hub for fun, fiesta and f...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Happy Cow Dairy</td>\n",
       "      <td>Agriculture, Farming</td>\n",
       "      <td>Seed</td>\n",
       "      <td>₹40,000,000</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>A startup which aggregates milk from dairy far...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MyLoanCare</td>\n",
       "      <td>Credit, Financial Services, Lending, Marketplace</td>\n",
       "      <td>Series A</td>\n",
       "      <td>₹65,000,000</td>\n",
       "      <td>Gurgaon, Haryana, India</td>\n",
       "      <td>Leading Online Loans Marketplace in India</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PayMe India</td>\n",
       "      <td>Financial Services, FinTech</td>\n",
       "      <td>Angel</td>\n",
       "      <td>2000000</td>\n",
       "      <td>Noida, Uttar Pradesh, India</td>\n",
       "      <td>PayMe India is an innovative FinTech organizat...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Eunimart</td>\n",
       "      <td>E-Commerce Platforms, Retail, SaaS</td>\n",
       "      <td>Seed</td>\n",
       "      <td>—</td>\n",
       "      <td>Hyderabad, Andhra Pradesh, India</td>\n",
       "      <td>Eunimart is a one stop solution for merchants ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     company_name                                           industry  \\\n",
       "0      0  TheCollegeFever  Brand Marketing, Event Promotion, Marketing, S...   \n",
       "1      1  Happy Cow Dairy                               Agriculture, Farming   \n",
       "2      2       MyLoanCare   Credit, Financial Services, Lending, Marketplace   \n",
       "3      3      PayMe India                        Financial Services, FinTech   \n",
       "4      4         Eunimart                 E-Commerce Platforms, Retail, SaaS   \n",
       "\n",
       "  funding_stage Amount_in_usd                          Location  \\\n",
       "0          Seed        250000       Bangalore, Karnataka, India   \n",
       "1          Seed   ₹40,000,000        Mumbai, Maharashtra, India   \n",
       "2      Series A   ₹65,000,000           Gurgaon, Haryana, India   \n",
       "3         Angel       2000000       Noida, Uttar Pradesh, India   \n",
       "4          Seed             —  Hyderabad, Andhra Pradesh, India   \n",
       "\n",
       "                                       about_company  year_funded  Founded  \\\n",
       "0  TheCollegeFever is a hub for fun, fiesta and f...         2018      NaN   \n",
       "1  A startup which aggregates milk from dairy far...         2018      NaN   \n",
       "2          Leading Online Loans Marketplace in India         2018      NaN   \n",
       "3  PayMe India is an innovative FinTech organizat...         2018      NaN   \n",
       "4  Eunimart is a one stop solution for merchants ...         2018      NaN   \n",
       "\n",
       "  Founders Investor  \n",
       "0      NaN      NaN  \n",
       "1      NaN      NaN  \n",
       "2      NaN      NaN  \n",
       "3      NaN      NaN  \n",
       "4      NaN      NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview the merged data\n",
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index             0.000000\n",
       "company_name      0.000000\n",
       "industry          0.630252\n",
       "funding_stage    32.528011\n",
       "Amount_in_usd     8.963585\n",
       "Location          3.991597\n",
       "about_company     0.000000\n",
       "year_funded       0.000000\n",
       "Founded          26.890756\n",
       "Founders         19.047619\n",
       "Investor         21.848739\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for percentage of null values \n",
    "merged_df.isna().mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the amount column \n",
    "- We consider the base value for the amount column to be dollars so any value in the amount column with no sign will be treated as a dollar value.\n",
    "- according to https://www.exchangerates.org.uk/INR-USD-spot-exchange-rates-history-2018.html, the average exchange rate for INR/USD in 2018 is ₹1 INR = $ 0.0146\n",
    "- we will strip the currency symbols, convert ruppes to dollar, remove the commas,- and convert datatype to float.\n",
    "-Certain rows in the amount column have wrong inputs which are values of other columns(like funding_stage and investor columns) and these rows must also be corrected.\n",
    "\n",
    "- undisclosed values will be treated as NaN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['250000', '₹40,000,000', '₹65,000,000', '2000000', '—', '1600000',\n",
       "       '₹16,000,000', '₹50,000,000', '₹100,000,000', '150000', '1100000',\n",
       "       '₹500,000', '6000000', '650000', '₹35,000,000', '₹64,000,000',\n",
       "       '₹20,000,000', '1000000', '5000000', '4000000', '₹30,000,000',\n",
       "       '2800000', '1700000', '1300000', '₹5,000,000', '₹12,500,000',\n",
       "       '₹15,000,000', '500000', '₹104,000,000', '₹45,000,000', '13400000',\n",
       "       '₹25,000,000', '₹26,400,000', '₹8,000,000', '₹60,000', '9000000',\n",
       "       '100000', '20000', '120000', '₹34,000,000', '₹342,000,000',\n",
       "       '$143,145', '₹600,000,000', '$742,000,000', '₹1,000,000,000',\n",
       "       '₹2,000,000,000', '$3,980,000', '$10,000', '₹100,000',\n",
       "       '₹250,000,000', '$1,000,000,000', '$7,000,000', '$35,000,000',\n",
       "       '₹550,000,000', '$28,500,000', '$2,000,000', '₹240,000,000',\n",
       "       '₹120,000,000', '$2,400,000', '$30,000,000', '₹2,500,000,000',\n",
       "       '$23,000,000', '$150,000', '$11,000,000', '₹44,000,000',\n",
       "       '$3,240,000', '₹60,000,000', '$540,000,000', '₹650,000,000',\n",
       "       '₹1,600,000,000', '$900,000', '$10,000,000', '$1,500,000',\n",
       "       '₹70,000,000', '$1,000,000', '$5,000,000', '$14,000,000',\n",
       "       '₹102,500,000', '$100,000,000', '₹1,200,000', '₹5,200,000,000',\n",
       "       '$800,000', '$1,041,000', '$100,000', '$15,000', '1400000',\n",
       "       '1200000', '2200000', '1800000', '3600000', '₹9,500,000', '300000',\n",
       "       '6830000', '200000', '₹150,000,000', '4300000', '364846', '400000',\n",
       "       '1500000', '₹7,000,000', '₹1,400,000', '₹10,000,000',\n",
       "       '₹22,500,000', '13200000', '50000', '₹140,200,000', '3000000',\n",
       "       '1250000', '180000', '₹19,200,000', '₹103,000,000', '4200000',\n",
       "       '175000', '1450000', '₹200,000', '4500000', '600000',\n",
       "       '₹16,600,000', '₹12,000,000', '15000000', '₹33,000,000', '125000',\n",
       "       '130000', '₹34,900,000', '₹72,000,000', '17200000', '₹32,000,000',\n",
       "       '3500000', '₹135,000,000', '12000000', '$40,000,000', '$1,100,000',\n",
       "       '$50,000,000', '₹1,540,000,000', '$3,000,000', '$6,000,000',\n",
       "       '₹140,000,000', '$41,900,000', '₹1,410,000,000', '$3,530,000',\n",
       "       '$200,000', '$3,300,000', '₹580,000,000', '₹36,000,000',\n",
       "       '₹340,000,000', '$210,000,000', '$37,680,000', '$250,000',\n",
       "       '$20,000', '₹510,000,000', '₹2,200,000,000', '22000000', '70000',\n",
       "       '10000000', '₹15,392,000,000', '₹20,000,000,000', '₹4,000,000,000',\n",
       "       '185000000', '65000000', '₹165,000,000', '700000', '30000000',\n",
       "       '₹210,000,000', '210000000', '₹2,029,600,000', '75000000',\n",
       "       '₹80,000,000', '1760000', '2700000', '₹280,000,000',\n",
       "       '₹800,000,000', '750000', '2500000', '80000000', '25000000',\n",
       "       '₹730,000,000', '₹400,000,000', '3700000', '5600000',\n",
       "       '₹260,000,000', '99230000', '70000000', '40000', '550000',\n",
       "       '50000000', '365000000', '₹8,750,000', '₹78,000,000', '28000000',\n",
       "       '₹264,000,000', '100000000', '₹1,130,000,000', '₹810,000,000',\n",
       "       '₹1,400,000,000', '14900000', '225000000', '7500', '35000000',\n",
       "       '$6,300,000 ', '$150,000,000 ', '$28,000,000 ', '$30,000,000 ',\n",
       "       '$6,000,000 ', 'Undisclosed', '$1,000,000 ', '$20,000,000 ',\n",
       "       '$275,000,000 ', '$22,000,000 ', '$5,000,000 ', '$140,500 ',\n",
       "       '$540,000,000 ', '$15,000,000 ', '$182,700 ', '$12,000,000 ',\n",
       "       '$11,000,000 ', '$15,500,000 ', '$1,500,000 ', '$5,500,000 ',\n",
       "       '$2,500,000 ', '$140,000 ', '$230,000,000 ', '$49,400,000 ',\n",
       "       '$32,000,000 ', '$26,000,000 ', '$150,000 ', '$400,000 ',\n",
       "       '$2,000,000 ', '$100,000,000 ', '$8,000,000 ', '$100,000 ',\n",
       "       '$50,000,000 ', '$120,000,000 ', '$4,000,000 ', '$6,800,000 ',\n",
       "       '$36,000,000 ', '$5,700,000 ', '$25,000,000 ', '$600,000 ',\n",
       "       '$70,000,000 ', '$60,000,000 ', '$220,000 ', '$2,800,000 ',\n",
       "       '$2,100,000 ', '$7,000,000 ', '$311,000,000 ', '$4,800,000 ',\n",
       "       '$693,000,000 ', '$33,000,000 ', 200000.0, 100000.0, nan, 400000.0,\n",
       "       340000.0, 600000.0, 45000000.0, 1000000.0, 2000000.0, 1200000.0,\n",
       "       660000000.0, 120000.0, 7500000.0, 5000000.0, 500000.0, 3000000.0,\n",
       "       10000000.0, 145000000.0, 100000000.0, 21000000.0, 4000000.0,\n",
       "       20000000.0, 560000.0, 275000.0, 4500000.0, 15000000.0, 390000000.0,\n",
       "       7000000.0, 5100000.0, 700000000.0, 2300000.0, 700000.0, 19000000.0,\n",
       "       9000000.0, 40000000.0, 750000.0, 1500000.0, 7800000.0, 50000000.0,\n",
       "       80000000.0, 30000000.0, 1700000.0, 2500000.0, 40000.0, 33000000.0,\n",
       "       35000000.0, 300000.0, 25000000.0, 3500000.0, 200000000.0,\n",
       "       6000000.0, 1300000.0, 4100000.0, 575000.0, 800000.0, 28000000.0,\n",
       "       18000000.0, 3200000.0, 900000.0, 250000.0, 4700000.0, 75000000.0,\n",
       "       8000000.0, 121000000.0, 55000000.0, 3300000.0, 11000000.0,\n",
       "       16000000.0, 5400000.0, 150000000.0, 4200000.0, 22000000.0,\n",
       "       52000000.0, 1100000.0, 118000000.0, 1600000.0, 18500000.0,\n",
       "       70000000000.0, 800000000.0, 400000000.0, 150000.0, 176000000.0,\n",
       "       60000000.0, 470000.0, 240000.0, 3000000000.0, 74000000.0,\n",
       "       62000000.0, 2100000.0, 500000000.0, 12500000.0, 2200000000.0,\n",
       "       5060000.0, 225000000.0, 24700000.0, 7700000.0, 19067328.0,\n",
       "       51000000.0, 115000.0, 54000.0, 20000.0, 803146.0, 238000.0,\n",
       "       10220000.0, 1020000.0, 12000000.0, 13400000.0, 170000000.0,\n",
       "       2900000.0, 543000.0, 90000000.0, 3400000.0, 23000000.0, 8090000.0,\n",
       "       1030000.0, 5040000.0, 360000.0, 1400000.0, 650000.0, 54000000.0,\n",
       "       42500000.0, 11370000.0, 325000.0, 410000.0, 450000.0, 682000.0,\n",
       "       4050000.0, 1050000.0, 1080000.0, 4300000.0, 6800000.0, 2110000.0,\n",
       "       764000.0, 603000.0, 409000.0, 292000.0, 286000.0, 136000.0,\n",
       "       546000.0, 887000.0, 43000.0, 40900.0, 2200000.0, 5660000.0,\n",
       "       350000.0, 110000.0, 122000000.0, 11635000.0, 2800000.0, 1065000.0,\n",
       "       669000.0, 16076000.0, 649600.0, 6700000.0, 220000.0, 266500.0,\n",
       "       2879000.0, 26500000.0, 351000.0, 46761000.0, 175000.0, 11241000.0,\n",
       "       804000.0, 1340000.0, 467000.0, 133000.0, 3823000.0, 934000.0,\n",
       "       293000.0, 198000.0, 927000.0, 971000.0, 3060000.0, 1862000.0,\n",
       "       232000.0, 2888000.0, 1328000.0, 15500000.0, 56000000.0, 2250000.0,\n",
       "       16753000.0, 3700000.0, 1470000.0, 530000.0, 267000.0, 3344000.0,\n",
       "       7200000.0, 2743000.0, 6082000.0, 6609000.0, 27700000.0, 5940000.0,\n",
       "       3964000.0, 5500000.0, 197000.0, 4327000.0, 459000.0, 3937000.0,\n",
       "       1313500.0, 229800.0, 5305000.0, 264000.0, 1750000.0, 5967000.0,\n",
       "       2980000.0, 323000.0, 1326000.0, 27000000.0, 5200000.0, 2530000.0,\n",
       "       792000.0, 11363000.0, 1715000.0, 329000.0, 5271000.0, 8700000.0,\n",
       "       3226000.0, 5900000.0, 44000000.0, 3879000.0, 13000000.0, 8800000.0,\n",
       "       9500000.0, 920000.0, 35600000.0, 9400000.0, 790000.0, 480000.0,\n",
       "       160000.0, 8200000.0, 4257000.0, 1410000.0, 349800.0, 786000.0,\n",
       "       2004000.0, 123000000.0, 248000.0, 24000000.0, 14259000.0,\n",
       "       24500000.0, 3800000.0, 18370000.0, 68525000.0, 4800000.0,\n",
       "       1834000.0, 23850000.0, 43000000.0, 21600000.0, 4598000.0,\n",
       "       13137000.0, 115000000.0, 3900000.0, 670000.0, 8500000.0, 3148000.0,\n",
       "       2600000.0, 4049500.0, 10500000.0, 6500000.0, 43700000.0,\n",
       "       13800000.0, 306900.0, 420000.0, 627300.0, 113000000.0, 32000000.0,\n",
       "       110000000.0, 1397000.0, 448500.0, 7975700.0, 330000.0, 5600000.0,\n",
       "       1402000.0, 21500000.0, 296000000.0, 4900000.0, 1402400.0,\n",
       "       12618300.0, 9900000.0, 982530.0, 70185200.0, 210000000.0,\n",
       "       84000000.0, 39000000.0, 2700000.0, 1403400.0, 105000000.0,\n",
       "       103000000.0, 281300.0, 12700.0, 25000.0, 97500000.0, 507000.0,\n",
       "       8400000.0, 18300000.0, 125000000.0, 181000.0, 280000.0, 14700000.0,\n",
       "       13200000.0, 8043000.0, '$1,200,000', '$120,000,000', '$51,000,000',\n",
       "       '$188,000,000', '$700,000', '$9,000,000', '$49,000,000',\n",
       "       '$400,000', '$300,000', '$25,000,000', '$160,000,000',\n",
       "       '$1,800,000', '$850,000', '$53,000,000', '$500,000', '$21,000,000',\n",
       "       '$7,500,000', '$26,000,000', '$7,400,000', '$600,000',\n",
       "       '$800,000,000', '$17,000,000', '$3,500,000', '$15,000,000',\n",
       "       '$215,000,000', '$2,500,000', '$350,000,000', '$5,500,000',\n",
       "       '$83,000,000', '$110,000,000', '$500,000,000', '$65,000,000',\n",
       "       '$150,000,000,000', '$300,000,000', '$2,200,000', '$140,000,000',\n",
       "       '$4,000,000', '$13,000,000', None, '$Undisclosed', '$2000000',\n",
       "       '$800000', '$6000000', '$2500000', '$9500000', '$13000000',\n",
       "       '$5000000', '$8000000', '$1000000', 'Upsparks', '$200000',\n",
       "       '$12000000', '$1500000', '$1700000', '$5500000', '$400000',\n",
       "       '$150000000', '$4000000', '$100000000', '$500000', '$15000000',\n",
       "       '$10000000', '$40000000', '$225000000', '$6700000', '$1300000',\n",
       "       '$20000000', '$250000', '$21000000', '$1200000', '$52000000',\n",
       "       '$3800000', '$17500000', '$42000000', '$2300000', '$7000000',\n",
       "       '$30000000', '$450000000', '$28000000', '$300000', '$3500000',\n",
       "       '$8500000', '$25000000', '$3000000', '$37000000', '$370000000',\n",
       "       '$700000', '$16000000', '$100000', '$44000000', '$770000',\n",
       "       '$125000000', '$35000000', '$50000000', '$4900000', '$145000000',\n",
       "       '$22000000', '$70000000', '$6600000', '$32000000', '$24000000',\n",
       "       '$725000', '$461000', 'Series C', 'Seed', '$96000000', '$60000000',\n",
       "       '$500000000', '$266000000', '$4500000', '$325000000', '$6500000',\n",
       "       '$1600000', '$150000', '$225000', '$85000000', '$235000',\n",
       "       '$260000', '$2900000', '$53000000', '$1100000', '$86000000',\n",
       "       '$130000', '$$100,00', '$111000000', '$265000', '$76000000',\n",
       "       '$75,000,000', '$3,800,000', '$12,000,000', '$1,600,000',\n",
       "       '$260,000', '$18,000,000', '$20,000,000', '$350,000',\n",
       "       '$95,000,000', '$4,100,000', '$5,200,000', '$8,000,000',\n",
       "       '$1,400,000', '$2,600,000', '$16,000,000', '$280,000,000',\n",
       "       '$14,300,000', '$81,000,000', '$1,300,000', '$8,200,000',\n",
       "       '$70,000,000', '$720,000', '$600000', '$9000000', '$1800000',\n",
       "       '$330000', '$undisclosed', '$200000000', '$36000000', '$67000000',\n",
       "       '$10200000', '$220000000', '$108000000', '$75000000', '$450000',\n",
       "       '$660000000', 'ah! Ventures', '$45000000', '$3200000', '$370000',\n",
       "       'Pre-series A', 'ITO Angel Network, LetsVenture', '$48000000',\n",
       "       '$3600000', '$11000000', '$192000000', '$65000000', '$1400000',\n",
       "       '$1900000', '$41000000', '$144000000', '$5200000', '$270000000',\n",
       "       '$140000', '$250000000', '$320000', '$350000000', '$4800000',\n",
       "       '$38000000', '$125000', '$26000000', '$64000000', '$620000',\n",
       "       '$900000', 'JITO Angel Network, LetsVenture', '$2600000',\n",
       "       '$1,250,000', '$400,000,000', '$1,700,000', '$27,000,000',\n",
       "       '$234,000,000', '$460,000,000', '$13,500,000', '$5,100,000',\n",
       "       '$195,000,000', '$125,000', '$45,000,000', '$200,000,000',\n",
       "       '$7,300,000', '$6,300,000', '$12,500,000', '$24,000,000',\n",
       "       '$140,000', '$16,500,000', '$340,000', '$43,000,000',\n",
       "       '$150,000,000', '$3300000', '$92000000', '$17000000', '$135000000',\n",
       "       '$$1,55,000', '$2100000', '$840000000', '$248000000', '$4300000',\n",
       "       '$570000', '$2200000', '$4700000', '$300000000', '$260000000',\n",
       "       '$140000000', '$175000000', '$19000000', '$810000', '$7500000',\n",
       "       '$600000000', '$90000000', '$5700000', '$6750000', '$78000000',\n",
       "       '$5400000', '$115000000', '$255000000', '$18000000', '$570000000',\n",
       "       '$550000', '$2700000', '$4200000', '$31000000', '$540000',\n",
       "       '$14000000', '$340000', '$', '$6200000', '$750000', '$6300000',\n",
       "       '$23000000', '$55000000'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the unique values in the Amount cloumn\n",
    "merged_df['Amount_in_usd'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Seed', 'Series A', 'Angel', 'Series B', 'Pre-Seed',\n",
       "       'Private Equity', 'Venture - Series Unknown', 'Grant',\n",
       "       'Debt Financing', 'Post-IPO Debt', 'Series H', 'Series C',\n",
       "       'Series E', 'Corporate Round', 'Undisclosed',\n",
       "       'https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593',\n",
       "       'Series D', 'Secondary Market', 'Post-IPO Equity',\n",
       "       'Non-equity Assistance', 'Funding Round', nan, 'Fresh funding',\n",
       "       'Pre series A', 'Series G', 'Post series A', 'Seed funding',\n",
       "       'Seed fund', 'Series F', 'Series B+', 'Seed round', 'Pre-series A',\n",
       "       None, 'Pre-seed', 'Pre-series', 'Debt', 'Pre-series C',\n",
       "       'Pre-series B', 'Bridge', 'Series B2', 'Pre- series A', 'Edge',\n",
       "       'Pre-Series B', 'Seed A', 'Series A-1', 'Seed Funding',\n",
       "       'Pre-seed Round', 'Seed Round & Series A', 'Pre Series A',\n",
       "       'Pre seed Round', 'Angel Round', 'Pre series A1', 'Series E2',\n",
       "       'Seed Round', 'Bridge Round', 'Pre seed round', 'Pre series B',\n",
       "       'Pre series C', 'Seed Investment', 'Series D1', 'Mid series',\n",
       "       'Series C, D', '$1200000', 'Seed+', 'Series F2', 'Series A+',\n",
       "       'Series B3', 'PE', 'Series F1', 'Pre-series A1', '$300000',\n",
       "       'Early seed', '$6000000', '$1000000', 'Seies A', 'Series A2',\n",
       "       'Series I'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['funding_stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         250000.0\n",
       "1         584000.0\n",
       "2         949000.0\n",
       "3        2000000.0\n",
       "4              NaN\n",
       "           ...    \n",
       "2851     3000000.0\n",
       "2852    20000000.0\n",
       "2853    55000000.0\n",
       "2854    26000000.0\n",
       "2855     8000000.0\n",
       "Name: Amount_in_usd, Length: 2856, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# initialize a list with all words in the amount column\n",
    "mist = ['None','Upsparks','Series C', 'Seed','ah! Ventures','Pre-series A', 'ITO Angel Network, LetsVenture','JITO Angel Network, LetsVenture']\n",
    "#get the index of the list \n",
    "mist_index = merged_df.index[merged_df['Amount_in_usd'].isin(mist)]\n",
    "#initialize a list of figures in funding_stage column\n",
    "stage_values = ['$1200000','$300000','$6000000','$1000000']\n",
    "#get the index of the list\n",
    "stage_index = merged_df.index[merged_df['funding_stage'].isin(stage_values)]\n",
    "#view entries in wrong columns which is the sum of the mist_index and stage_index\n",
    "merged_df.loc[[1764, 1903, 1904, 2185, 2192, 2198, 2321,2324, 2795]]\n",
    "\n",
    "#correct entries in the wrong columns by creating a list\n",
    "corrections ={\n",
    "        1764: {'Amount_in_usd':'$1200000','Investor':'Upsparks','Location':'undisclosed','Founders':'Pritesh Kumar, Bharat Gupta','funding_stage':'undisclosed'},\n",
    "        1903: {'Amount_in_usd':'$22000000','Investor':'Morgan Stanley Private Equity Asia',\n",
    "              'Location':'None','Founders':'Varun Khanna','industry':'Pharmaceuticals',\n",
    "              'funding_stage':'Series C','about_company':'Development and Manufacturing'},\n",
    "        1904: {'Amount_in_usd':'$5000000','Investor':'Anshuman Maheshwary, Dr Srihari Raju Kalidindi','Founders':'Vikash Mishra, Mragank Jain',\n",
    "              'industry':'None','funding_stage':'Seed',\n",
    "              'about_company':\"MoEVing is India's only Electric Mobility focu..\"},\n",
    "        2185: {'Amount_in_usd':'$300000','Investor':'ah! Ventures','Founders':'Vishal Gupta',\n",
    "              'funding_stage':'None','about_company':'Holistic Development Programs for children in Soft Skills that make Smart Leaders'},\n",
    "        2192: {'Amount_in_usd':'$1000000','funding_stage':'Pre-series A','Investor':'None'},\n",
    "        2198: {'Amount_in_usd':'$300000','Investor':'JITO Angel Network, LetsVenture','Founders':'Omkar Pandharkame, Ketaki Ogale',\n",
    "             'funding_stage':'None'},\n",
    "       2321: {'Amount_in_usd':'$6000000','funding_stage':'None'},\n",
    "       2324: {'Amount_in_usd':'$1000000','Investor':'JITO Angel Network, LetsVenture','funding_stage':'None'},\n",
    "       2795:{'Amount_in_usd':'1000000','funding_stage':'Seed','Investor':'None'}\n",
    "}\n",
    "\n",
    "# Loop through each index and update the values\n",
    "for index, new_values in corrections.items():\n",
    "    for column, value in new_values.items():\n",
    "        if column in merged_df.columns:\n",
    "            merged_df.at[index, column] = value\n",
    "\n",
    "\n",
    "\n",
    "# Preview rows with amount vales showing $Undisclosed, $undisclosed, and Undisclosed\n",
    "undisclosed_list = ['$Undisclosed', '$undisclosed', 'Undisclosed']\n",
    "\n",
    "# Get the index for all rows with undisclosed\n",
    "undisclosed_index = merged_df.index[merged_df['Amount_in_usd'].isin(undisclosed_list)]\n",
    "\n",
    "# Replace undisclosed values with NA\n",
    "merged_df.loc[undisclosed_index, ['Amount_in_usd']] = merged_df.loc[undisclosed_index, ['Amount_in_usd']].replace(undisclosed_list, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_amount(amount):\n",
    "    \"\"\"\n",
    "    Cleans the 'Amount_in_usd' column by removing unwanted symbols and converting to float.\n",
    "    If the amount is in rupees (₹), it converts to USD.\n",
    "    \"\"\"\n",
    "    if isinstance(amount, str):\n",
    "        # Remove unwanted symbols\n",
    "        clean_amount = amount.replace('$', '').replace('₹', '').replace(',', '').replace('-', 'np.nan')\n",
    "        # Convert to float\n",
    "        try:\n",
    "            clean_amount = float(clean_amount)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "        # Convert rupees to USD if applicable\n",
    "        if '₹' in amount:\n",
    "            clean_amount *= 0.0146\n",
    "        return clean_amount\n",
    "    elif isinstance(amount, (int, float)):\n",
    "        return float(amount)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "merged_df['Amount_in_usd'] = merged_df['Amount_in_usd'].apply(clean_amount)\n",
    "\n",
    "merged_df['Amount_in_usd']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "merged_df['Amount_in_usd'].isna().sum()\n",
    "\n",
    "#the null values include undisclosed amount, we will fill the median considering outliers and skewness\n",
    "\n",
    "merged_df['Amount_in_usd'].fillna(merged_df['Amount_in_usd'].median(), inplace=True)\n",
    "\n",
    "merged_df['Amount_in_usd'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the location column\n",
    "- wrong entries from other columns found in location and has to be corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bangalore, Karnataka, India', 'Mumbai, Maharashtra, India',\n",
       "       'Gurgaon, Haryana, India', 'Noida, Uttar Pradesh, India',\n",
       "       'Hyderabad, Andhra Pradesh, India', 'Bengaluru, Karnataka, India',\n",
       "       'Kalkaji, Delhi, India', 'Delhi, Delhi, India', 'India, Asia',\n",
       "       'Hubli, Karnataka, India', 'New Delhi, Delhi, India',\n",
       "       'Chennai, Tamil Nadu, India', 'Mohali, Punjab, India',\n",
       "       'Kolkata, West Bengal, India', 'Pune, Maharashtra, India',\n",
       "       'Jodhpur, Rajasthan, India', 'Kanpur, Uttar Pradesh, India',\n",
       "       'Ahmedabad, Gujarat, India', 'Azadpur, Delhi, India',\n",
       "       'Haryana, Haryana, India', 'Cochin, Kerala, India',\n",
       "       'Faridabad, Haryana, India', 'Jaipur, Rajasthan, India',\n",
       "       'Kota, Rajasthan, India', 'Anand, Gujarat, India',\n",
       "       'Bangalore City, Karnataka, India', 'Belgaum, Karnataka, India',\n",
       "       'Thane, Maharashtra, India', 'Margão, Goa, India',\n",
       "       'Indore, Madhya Pradesh, India', 'Alwar, Rajasthan, India',\n",
       "       'Kannur, Kerala, India', 'Trivandrum, Kerala, India',\n",
       "       'Ernakulam, Kerala, India', 'Kormangala, Karnataka, India',\n",
       "       'Uttar Pradesh, India, Asia', 'Andheri, Maharashtra, India',\n",
       "       'Mylapore, Tamil Nadu, India', 'Ghaziabad, Uttar Pradesh, India',\n",
       "       'Kochi, Kerala, India', 'Powai, Assam, India',\n",
       "       'Guntur, Andhra Pradesh, India', 'Kalpakkam, Tamil Nadu, India',\n",
       "       'Bhopal, Madhya Pradesh, India', 'Coimbatore, Tamil Nadu, India',\n",
       "       'Worli, Maharashtra, India', 'Alleppey, Kerala, India',\n",
       "       'Chandigarh, Chandigarh, India', 'Guindy, Tamil Nadu, India',\n",
       "       'Lucknow, Uttar Pradesh, India', nan, 'Mumbai', 'Chennai',\n",
       "       'Telangana', 'Pune', 'Bangalore', 'Noida', 'Delhi', 'Ahmedabad',\n",
       "       'Gurugram', 'Haryana', 'Chandigarh', 'Jaipur', 'New Delhi',\n",
       "       'Surat', 'Uttar pradesh', 'Hyderabad', 'Rajasthan', 'Indore',\n",
       "       'Gurgaon', 'Belgaum', 'Andheri', 'Kolkata',\n",
       "       'Tirunelveli, Tamilnadu', 'Thane', None, 'Singapore', 'Gujarat',\n",
       "       'Kerala', 'Jodhpur', 'Jaipur, Rajastan',\n",
       "       'Frisco, Texas, United States', 'California', 'Dhingsara, Haryana',\n",
       "       'New York, United States', 'Patna',\n",
       "       'San Francisco, California, United States',\n",
       "       'San Francisco, United States', 'San Ramon, California',\n",
       "       'Paris, Ile-de-France, France', 'Plano, Texas, United States',\n",
       "       'Sydney', 'San Francisco Bay Area, Silicon Valley, West Coast',\n",
       "       'Bangaldesh', 'London, England, United Kingdom',\n",
       "       'Sydney, New South Wales, Australia', 'Milano, Lombardia, Italy',\n",
       "       'Palmwoods, Queensland, Australia', 'France',\n",
       "       'San Francisco Bay Area, West Coast, Western US', 'Cochin',\n",
       "       'Samastipur, Bihar', 'Irvine, California, United States',\n",
       "       'Tumkur, Karnataka',\n",
       "       'Newcastle Upon Tyne, Newcastle upon Tyne, United Kingdom',\n",
       "       'Shanghai, China', 'Jiaxing, Zhejiang, China', 'Rajastan', 'Kochi',\n",
       "       'Ludhiana', 'Dehradun', 'San Franciscao', 'San Francisco',\n",
       "       'Tangerang, Jawa Barat, Indonesia', 'Berlin', 'Seattle', 'Riyadh',\n",
       "       'Seoul', 'New York', 'Bangkok', 'Kanpur', 'Warangal', 'Hyderebad',\n",
       "       'Odisha', 'Bihar', 'Goa', 'Tamil Nadu', 'Uttar Pradesh', 'Bhopal',\n",
       "       'Banglore', 'Coimbatore', 'Bengaluru', 'Ahmadabad',\n",
       "       'Small Towns, Andhra Pradesh', 'Rajsamand', 'Ranchi',\n",
       "       'Faridabad, Haryana', 'undisclosed', 'Vadodara',\n",
       "       'Food & Beverages', 'None', 'Gurugram\\t#REF!', 'Mohali', 'Powai',\n",
       "       'Ghaziabad', 'Nagpur', 'West Bengal', 'Samsitpur', 'Lucknow',\n",
       "       'Silvassa', 'Thiruvananthapuram', 'Faridabad', 'Roorkee',\n",
       "       'Ambernath', 'Panchkula', 'Mangalore', 'Telugana', 'Bhubaneswar',\n",
       "       'Kottayam', 'Beijing', 'Panaji', 'Satara', 'Orissia', 'Santra',\n",
       "       'Mountain View, CA', 'Trivandrum', 'Jharkhand', 'Bhilwara',\n",
       "       'Guwahati', 'Online Media\\t#REF!', 'London',\n",
       "       'Information Technology & Services', 'The Nilgiris', 'Gandhinagar'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check unique values in the location column\n",
    "merged_df.Location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bangalore', 'Mumbai', 'Gurgaon', 'Noida', 'Hyderabad',\n",
       "       'Bengaluru', 'Kalkaji', 'Delhi', 'India', 'Hubli', 'New Delhi',\n",
       "       'Chennai', 'Mohali', 'Kolkata', 'Pune', 'Jodhpur', 'Kanpur',\n",
       "       'Ahmedabad', 'Azadpur', 'Haryana', 'Cochin', 'Faridabad', 'Jaipur',\n",
       "       'Kota', 'Anand', 'Bangalore City', 'Belgaum', 'Thane', 'Margão',\n",
       "       'Indore', 'Alwar', 'Kannur', 'Trivandrum', 'Ernakulam',\n",
       "       'Kormangala', 'Uttar Pradesh', 'Andheri', 'Mylapore', 'Ghaziabad',\n",
       "       'Kochi', 'Powai', 'Guntur', 'Kalpakkam', 'Bhopal', 'Coimbatore',\n",
       "       'Worli', 'Alleppey', 'Chandigarh', 'Guindy', 'Lucknow', nan,\n",
       "       'Telangana', 'Gurugram', 'Surat', 'Uttar pradesh', 'Rajasthan',\n",
       "       'Tirunelveli', None, 'Singapore', 'Gujarat', 'Kerala', 'Frisco',\n",
       "       'California', 'Dhingsara', 'New York', 'Patna', 'San Francisco',\n",
       "       'San Ramon', 'Paris', 'Plano', 'Sydney', 'San Francisco Bay Area',\n",
       "       'Bangaldesh', 'London', 'Milano', 'Palmwoods', 'France',\n",
       "       'Samastipur', 'Irvine', 'Tumkur', 'Newcastle Upon Tyne',\n",
       "       'Shanghai', 'Jiaxing', 'Rajastan', 'Ludhiana', 'Dehradun',\n",
       "       'San Franciscao', 'Tangerang', 'Berlin', 'Seattle', 'Riyadh',\n",
       "       'Seoul', 'Bangkok', 'Warangal', 'Hyderebad', 'Odisha', 'Bihar',\n",
       "       'Goa', 'Tamil Nadu', 'Banglore', 'Ahmadabad', 'Small Towns',\n",
       "       'Rajsamand', 'Ranchi', 'undisclosed', 'Vadodara', 'Hauz Khas',\n",
       "       'None', 'Gurugram\\t#REF!', 'Nagpur', 'West Bengal', 'Samsitpur',\n",
       "       'Silvassa', 'Thiruvananthapuram', 'Roorkee', 'Ambernath',\n",
       "       'Panchkula', 'Mangalore', 'Telugana', 'Bhubaneswar', 'Kottayam',\n",
       "       'Beijing', 'Panaji', 'Satara', 'Orissia', 'Santra',\n",
       "       'Mountain View', 'Jharkhand', 'Bhilwara', 'Guwahati', 'Manchester',\n",
       "       'The Nilgiris', 'Gandhinagar'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wrong entries from other columns found in location and has to be corrected.\n",
    "# initialize a list with all wrong entries  in the locattion column\n",
    "wrong_loc = ['Food & Beverages','Online Media\\t#REF!', 'Information Technology & Services']\n",
    "#get the index of the list \n",
    "wrong_loc_index = merged_df.index[merged_df['Location'].isin(wrong_loc)]\n",
    "#view entries in wrong columns and correct them\n",
    "merged_df.loc[[1902, 2747, 2823]]\n",
    "#correct entries in the wrong columns by creating a list\n",
    "correct_entries ={\n",
    "                1902: {'industry':'Food & Beverages','Location':'Hauz Khas'},\n",
    "                2747: {'industry':'Online Media','Location':'None',\n",
    "                        'Founders':'CA Harvinderjit Singh Bhatia, Garima Surana, A',\n",
    "                      'about_company':'Sochcast is an Audio experiences company that ...',\n",
    "                       'Investor':'Vinners, Raj Nayak, Amritaanshu Agrawal'},\n",
    "                2823: {'industry':'Information Technology & Services','Location':'Manchester, Greater Manchester'}\n",
    "                }\n",
    "# Loop through each index and update the values\n",
    "for index, new_values in correct_entries.items():\n",
    "    for column, value in new_values.items():\n",
    "        if column in merged_df.columns:\n",
    "            merged_df.at[index, column] = value\n",
    "\n",
    "\n",
    "# # Split the location Column into City, State and Country\n",
    "merged_df[[\"city\", \"state\",\"country\"]] = merged_df[\"Location\"].str.split(\",\", n=2, expand=True)\n",
    "\n",
    "merged_df[\"city\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning the city column\n",
    "#Azadpur is a locality located in Delhi city,Kalkaji is a localty in south delhi,Koramangala is a locality in Bangalore\n",
    "#Kochi or Cochin or Ernakulam is part of the district of Ernakulam in the state of Kerala,\n",
    "#Uttar pradesh is a state,Rajasthan is a state,Dhingsara is a village in Haryana state,Warangal is a district in Telangana state\n",
    "#Odisha is a state,Bihar is a state,Hauz Khas is a neighborhood in South Delhi,Samastipur is a city in Bihar\n",
    "#map santra to satara "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove \\t#REF! from city column\n",
    "merged_df['city'] = merged_df['city'].str.replace('\\t#REF!','')\n",
    "\n",
    "#define a function to correct city names wrongly spelt and mapped\n",
    "def fix_city(cities):\n",
    "    # Dictionary mapping incorrect city names to correct ones\n",
    "    correct_city = {\n",
    "        'Bengaluru': 'Bangalore',\n",
    "        'Bangalore City': 'Bangalore',\n",
    "        'Banglore': 'Bangalore',\n",
    "        'Hyderebad': 'Hyderabad',\n",
    "        'Gurgaon': 'Gurugram',\n",
    "        'Thiruvananthapuram':'Trivandrum',\n",
    "        'Kochi': 'Cochin',\n",
    "        'Kormangala': 'Bangalore',\n",
    "        'Ahmadabad': 'Ahmedabad',\n",
    "        'Rajastan': 'Rajasthan',\n",
    "        'Telugana': 'Telangana',\n",
    "        'Orissia': 'Odisha',\n",
    "        'Samsitpur': 'Samastipur',\n",
    "        'San Franciscao': 'San Francisco',\n",
    "        'San Francisco Bay Area': 'San Francisco',\n",
    "        'Kalkaji': 'Delhi',\n",
    "        'Azadpur': 'Delhi',\n",
    "        'New Delhi': 'Delhi',\n",
    "        'Bangaldesh': 'Bangladesh',\n",
    "        'Santra':'Satara',\n",
    "        'Warangal': 'Warangal',\n",
    "        'Hauz Khas': 'Delhi',\n",
    "        'Small Towns': 'unknown',\n",
    "        'undisclosed': 'unknown'\n",
    "    }\n",
    "    return correct_city.get(cities, cities)\n",
    "\n",
    "#apply correction to city column\n",
    "merged_df['city'] = merged_df['city'].apply(fix_city)\n",
    "\n",
    "#correct entries in city column where state is found at different rows\n",
    "state_in_city = ['Uttar pradesh', 'Rajasthan','Odisha', 'Bihar','Telangana','Goa','Kerala','Tamil Nadu','Haryana','Gujarat','Punjab','Karnataka','Madhya Pradesh','Andhra Pradesh','Chandigarh','Uttarakhand','Jharkhand','West Bengal','Dadra and Nagar Haveli and Daman and Diu']\n",
    "\n",
    "state_index = merged_df.index[merged_df['city'].isin(state_in_city)]\n",
    "\n",
    "#index positions of states found in city column\n",
    "state_index = [84,  102,  142,  289,  417,  420,  426,  433,  469,  480,  492,  521,529,551,  557,607,613,  712,  \n",
    "               716,  718,724,  740,  766,  787,923,  945,  960,  978, 1082, 1112,1207,1241,1307, 1315,1338, 1364,\n",
    "               1370,1376, 1485, 1487, 1492, 1592,1602, 1639,1702, 1723, 1808,1839, 1981, 1989,1991, 2029, 2084,\n",
    "               2087, 2097, 2315,2362, 2405,2491, 2501, 2556, 2603, 2721]\n",
    "\n",
    "# Swap City and State values at the specified index positions\n",
    "for idx in state_index:\n",
    "    if idx < len(merged_df):\n",
    "        merged_df.at[idx, 'state'], merged_df.at[idx, 'city'] = merged_df.at[idx, 'city'],np.nan\n",
    "\n",
    "#countries in city column\n",
    "country_in_city = ['India','Singapore','Bangladesh','France']\n",
    "\n",
    "#locate the index positions of countries in city column\n",
    "country_index = merged_df.index[merged_df['city'].isin(country_in_city)]\n",
    "\n",
    "country_index = [12, 42, 59, 199, 705, 857, 886, 1011, 1069, 1094]\n",
    "\n",
    "# Swap City and country values at the specified index positions\n",
    "for idx in country_index:\n",
    "    if idx < len(merged_df):\n",
    "        merged_df.at[idx, 'country'], merged_df.at[idx, 'city'] = merged_df.at[idx, 'city'],np.nan\n",
    "    \n",
    "#change None to Nan and covert to string data type\n",
    "merged_df['city'] = merged_df['city'].replace('None', 'nan').astype('str')\n",
    "merged_df['city'] = merged_df['city'].replace('nan','unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " number of missing value is :0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Bangalore', 'Mumbai', 'Gurugram', 'Noida', 'Hyderabad', 'Delhi',\n",
       "       'unknown', 'Hubli', 'Chennai', 'Mohali', 'Kolkata', 'Pune',\n",
       "       'Jodhpur', 'Kanpur', 'Ahmedabad', 'Cochin', 'Faridabad', 'Jaipur',\n",
       "       'Kota', 'Anand', 'Belgaum', 'Thane', 'Margão', 'Indore', 'Alwar',\n",
       "       'Kannur', 'Trivandrum', 'Ernakulam', 'Uttar Pradesh', 'Andheri',\n",
       "       'Mylapore', 'Ghaziabad', 'Powai', 'Guntur', 'Kalpakkam', 'Bhopal',\n",
       "       'Coimbatore', 'Worli', 'Alleppey', 'Guindy', 'Lucknow', 'Surat',\n",
       "       'Tirunelveli', 'None', 'Frisco', 'California', 'Dhingsara',\n",
       "       'New York', 'Patna', 'San Francisco', 'San Ramon', 'Paris',\n",
       "       'Plano', 'Sydney', 'London', 'Milano', 'Palmwoods', 'Samastipur',\n",
       "       'Irvine', 'Tumkur', 'Newcastle Upon Tyne', 'Shanghai', 'Jiaxing',\n",
       "       'Ludhiana', 'Dehradun', 'Tangerang', 'Berlin', 'Seattle', 'Riyadh',\n",
       "       'Seoul', 'Bangkok', 'Warangal', 'Rajsamand', 'Ranchi', 'Vadodara',\n",
       "       'Nagpur', 'Silvassa', 'Roorkee', 'Ambernath', 'Panchkula',\n",
       "       'Mangalore', 'Bhubaneswar', 'Kottayam', 'Beijing', 'Panaji',\n",
       "       'Satara', 'Mountain View', 'Bhilwara', 'Guwahati', 'Manchester',\n",
       "       'The Nilgiris', 'Gandhinagar'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "print(f\" number of missing value is :{merged_df['city'].isna().sum()}\")\n",
    "\n",
    "# Display the cleaned city columns\n",
    "merged_df['city'].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the state column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Karnataka', ' Maharashtra', ' Haryana', ' Uttar Pradesh',\n",
       "       ' Andhra Pradesh', ' Delhi', ' Asia', ' Tamil Nadu', ' Punjab',\n",
       "       ' West Bengal', ' Rajasthan', ' Gujarat', 'Haryana', ' Kerala',\n",
       "       ' Goa', ' Madhya Pradesh', ' India', ' Assam', 'Chandigarh', nan,\n",
       "       None, 'Telangana', 'Uttar pradesh', 'Rajasthan', ' Tamilnadu',\n",
       "       'Gujarat', 'Kerala', ' Rajastan', ' Texas', ' United States',\n",
       "       ' California', ' Ile-de-France', ' Silicon Valley', ' England',\n",
       "       ' New South Wales', ' Lombardia', ' Queensland', ' West Coast',\n",
       "       ' Bihar', ' Newcastle upon Tyne', ' China', ' Zhejiang',\n",
       "       ' Jawa Barat', 'Odisha', 'Bihar', 'Goa', 'Tamil Nadu',\n",
       "       'West Bengal', ' CA', 'Jharkhand', ' Greater Manchester'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view the state column unique values\n",
    "merged_df['state'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Karnataka', 'Maharashtra', 'Haryana', 'Uttar Pradesh',\n",
       "       'Andhra Pradesh', 'Delhi', 'Asia', 'Tamil Nadu', 'Punjab',\n",
       "       'West Bengal', 'Rajasthan', 'Gujarat', 'Kerala', 'Goa',\n",
       "       'Madhya Pradesh', 'nan', 'Assam', 'Chandigarh', 'None',\n",
       "       'Telangana', 'Texas', 'California', 'Île-de-France',\n",
       "       'Silicon Valley', 'England', 'New South Wales', 'Lombardy',\n",
       "       'Queensland', 'West Coast', 'Bihar', 'Newcastle upon Tyne',\n",
       "       'Zhejiang', 'Jawa Barat', 'Odisha', 'Jharkhand',\n",
       "       'Greater Manchester'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove whitespaces and replace None wih Nan\n",
    "merged_df['state'] = merged_df['state'].str.strip().replace('None', np.nan)\n",
    "\n",
    "# Define a mapping of incorrect to correct state names\n",
    "def fix_state(states):\n",
    "    state_mapping = {'Uttar pradesh': 'Uttar Pradesh',\n",
    "                    'Tamilnadu': 'Tamil Nadu',\n",
    "                    'Rajastan': 'Rajasthan', \n",
    "                   'Ile-de-France': 'Île-de-France', \n",
    "                   'Lombardia': 'Lombardy',\n",
    "                  'CA': 'California'}\n",
    "    return state_mapping.get(states, states)\n",
    "\n",
    "# Correct the state names\n",
    "merged_df['state'] = merged_df['state'].apply(fix_state)\n",
    "\n",
    "\n",
    "#countries in state column\n",
    "country_in_state = ['India','United States','China']\n",
    "\n",
    "#locate the index positions of countries in state column\n",
    "countries_index = merged_df.index[merged_df['state'].isin(country_in_state)]\n",
    "\n",
    "countries_index = [240, 799, 837, 876, 915]\n",
    "\n",
    "# Swap state and country values at the specified index positions\n",
    "for idx in countries_index:\n",
    "    if idx < len(merged_df):\n",
    "        merged_df.at[idx, 'country'], merged_df.at[idx, 'state'] = merged_df.at[idx, 'state'],np.nan\n",
    "    \n",
    "#change None to Nan and covert to string data type\n",
    "merged_df['state'] = merged_df['state'].replace('None', 'Nan').astype('str')\n",
    "\n",
    "\n",
    "# # # Get only the countries from the 'State' column\n",
    "# # countries = merged_df[merged_df['state'].apply(lambda x: isinstance(x, str))]['state'].unique()\n",
    "# # countries\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "merged_df['state'].unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "merged_df['state'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Karnataka', 'Maharashtra', 'Haryana', 'Uttar Pradesh',\n",
       "       'Telangana', 'Delhi', nan, 'Tamil Nadu', 'Punjab', 'West Bengal',\n",
       "       'Rajasthan', 'Gujarat', 'Kerala', 'Goa', 'Madhya Pradesh',\n",
       "       'Andhra Pradesh', 'Bihar', 'Jharkhand',\n",
       "       'Dadra and Nagar Haveli and Daman and Diu', 'Uttarakhand',\n",
       "       'Odisha', 'Assam'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will map cities to state and fill the na\n",
    "\n",
    "# Dictionary to map cities to their respective states\n",
    "city_to_state = {\n",
    "    'Bangalore': 'Karnataka', 'Mumbai': 'Maharashtra', 'Gurugram': 'Haryana', 'Noida': 'Uttar Pradesh',\n",
    "    'Hyderabad': 'Telangana', 'Delhi': 'Delhi', 'Hubli': 'Karnataka', 'Chennai': 'Tamil Nadu',\n",
    "    'Mohali': 'Punjab', 'Kolkata': 'West Bengal', 'Pune': 'Maharashtra', 'Jodhpur': 'Rajasthan',\n",
    "    'Kanpur': 'Uttar Pradesh', 'Ahmedabad': 'Gujarat', 'Cochin': 'Kerala', 'Faridabad': 'Haryana',\n",
    "    'Jaipur': 'Rajasthan', 'Kota': 'Rajasthan', 'Anand': 'Gujarat', 'Belgaum': 'Karnataka',\n",
    "    'Thane': 'Maharashtra', 'Margão': 'Goa', 'Indore': 'Madhya Pradesh', 'Alwar': 'Rajasthan',\n",
    "    'Kannur': 'Kerala', 'Trivandrum': 'Kerala', 'Ernakulam': 'Kerala', 'Uttar Pradesh': 'Uttar Pradesh',\n",
    "    'Andheri': 'Maharashtra', 'Mylapore': 'Tamil Nadu', 'Ghaziabad': 'Uttar Pradesh', 'Powai': 'Maharashtra',\n",
    "    'Guntur': 'Andhra Pradesh', 'Kalpakkam': 'Tamil Nadu', 'Bhopal': 'Madhya Pradesh', 'Coimbatore': 'Tamil Nadu',\n",
    "    'Worli': 'Maharashtra', 'Alleppey': 'Kerala', 'Guindy': 'Tamil Nadu', 'Lucknow': 'Uttar Pradesh',\n",
    "    'Surat': 'Gujarat', 'Tirunelveli': 'Tamil Nadu', 'Warangal': 'Telangana', 'Rajsamand': 'Rajasthan',\n",
    "    'Ranchi': 'Jharkhand', 'Vadodara': 'Gujarat', 'Nagpur': 'Maharashtra', 'Silvassa': 'Dadra and Nagar Haveli and Daman and Diu',\n",
    "    'Roorkee': 'Uttarakhand', 'Ambernath': 'Maharashtra', 'Panchkula': 'Haryana', 'Mangalore': 'Karnataka',\n",
    "    'Bhubaneswar': 'Odisha', 'Kottayam': 'Kerala', 'Panaji': 'Goa', 'Satara': 'Maharashtra',\n",
    "    'Bhilwara': 'Rajasthan', 'Guwahati': 'Assam', 'The Nilgiris': 'Tamil Nadu', 'Gandhinagar': 'Gujarat',\n",
    "    'Patna': 'Bihar', 'Samastipur': 'Bihar', 'Tumkur': 'Karnataka'\n",
    "}\n",
    "\n",
    "# # Map the cities to their respective states\n",
    "merged_df['state'] = merged_df['city'].map(city_to_state)\n",
    "\n",
    "# # # Replace 'nan' and 'None' values in the City column with np.nan\n",
    "# merged_df['city'].replace(['nan', 'None', 'unknown'], np.nan, inplace=True)\n",
    "\n",
    "# Replace np.nan in the State column with the mapped state from the City column\n",
    "merged_df['state'].fillna(merged_df['city'].map(city_to_state),inplace = True)\n",
    "\n",
    "# Replace 'nan' values in the State column with unknown\n",
    "merged_df['state'].str.replace('nan','unknown').replace(' ','unknown')\n",
    "\n",
    "# Display the DataFrame\n",
    "\n",
    "merged_df['state'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['state'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' India', 'India', nan, None, 'Singapore', ' United States',\n",
       "       'United States', ' France', ' West Coast', 'Bangladesh',\n",
       "       ' United Kingdom', ' Australia', ' Italy', 'France', ' Western US',\n",
       "       'China', ' China', ' Indonesia'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning the country column\n",
    "\n",
    "merged_df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['India', nan, 'Singapore', 'United States', 'France', 'West Coast',\n",
       "       'Bangladesh', 'United Kingdom', 'Australia', 'Italy', 'Western US',\n",
       "       'China', 'Indonesia'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove whitespaces\n",
    "merged_df['country'] = merged_df['country'].str.strip()\n",
    "# Dictionary to map states to their respective countries\n",
    "state_to_country = {\n",
    "    'Karnataka': 'India', 'Maharashtra': 'India', 'Haryana': 'India', 'Uttar Pradesh': 'India',\n",
    "    'Telangana': 'India', 'Delhi': 'India', 'Tamil Nadu': 'India', 'Punjab': 'India',\n",
    "    'West Bengal': 'India', 'Rajasthan': 'India', 'Gujarat': 'India', 'Kerala': 'India',\n",
    "    'Goa': 'India', 'Madhya Pradesh': 'India', 'Andhra Pradesh': 'India', 'Bihar': 'India',\n",
    "    'Jharkhand': 'India', 'Dadra and Nagar Haveli and Daman and Diu': 'India', 'Uttarakhand': 'India',\n",
    "    'Odisha': 'India', 'Assam': 'India', 'Unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "# Map the states to their respective countries\n",
    "merged_df['country'] = merged_df['country'].fillna(merged_df['state'].map(state_to_country))\n",
    "# # Map the states to their respective countries\n",
    "# df['Country'] = df['Country'].fillna(df['State'].map(state_to_country))\n",
    "\n",
    "# Display the DataFrame\n",
    "merged_df['country'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the location column\n",
    "merged_df.drop(columns='Location',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the Industry Column\n",
    "From research, there are 15 sectors in India where all these values in the sector column of the dataset can be generalised into. They are therefore mapped onto the 15 sectors which include:\n",
    "\n",
    "IT & Technology\n",
    "Financial Services\n",
    "Healthcare & Life Sciences\n",
    "Consumer Goods\n",
    "Business Services\n",
    "Media & Entertainment\n",
    "Education\n",
    "Manufacturing\n",
    "Retail\n",
    "Transportation & Logistics\n",
    "Sports\n",
    "Agriculture\n",
    "Real Estate\n",
    "Travel & Tourism\n",
    "Energy\n",
    "Others\n",
    "source: https://www.businessinsider.in/business/startups/news/top-10-industries-for-new-startups-in-india-as-per-hurun-list/articleshow/105651758.cms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Brand Marketing, Event Promotion, Marketing, Sponsorship, Ticketing',\n",
       "       'Agriculture, Farming',\n",
       "       'Credit, Financial Services, Lending, Marketplace',\n",
       "       'Financial Services, FinTech',\n",
       "       'E-Commerce Platforms, Retail, SaaS',\n",
       "       'Cloud Infrastructure, PaaS, SaaS',\n",
       "       'Internet, Leisure, Marketplace', 'Market Research',\n",
       "       'Information Services, Information Technology', 'Mobile Payments',\n",
       "       'B2B, Shoes', 'Internet',\n",
       "       'Apps, Collaboration, Developer Platform, Enterprise Software, Messaging, Productivity Tools, Video Chat',\n",
       "       'Food Delivery', 'Industrial Automation',\n",
       "       'Automotive, Search Engine, Service Industry',\n",
       "       'Finance, Internet, Travel',\n",
       "       'Accounting, Business Information Systems, Business Travel, Finance, SaaS',\n",
       "       'Artificial Intelligence, Product Search, SaaS, Service Industry, Software',\n",
       "       'Internet of Things, Waste Management',\n",
       "       'Air Transportation, Freight Service, Logistics, Marine Transportation',\n",
       "       'Financial Services', 'Food and Beverage', 'Autonomous Vehicles',\n",
       "       'Enterprise Software, Health Care, Hospital, Parenting, Personal Health, SaaS',\n",
       "       'Agriculture, Analytics, Big Data, Farming',\n",
       "       'Logistics, Supply Chain Management',\n",
       "       'Financial Services, Lending',\n",
       "       'Automotive, Marketplace, Online Portals',\n",
       "       'Artificial Intelligence',\n",
       "       'Internet of Things, Telecommunications', 'Insurance',\n",
       "       'Information Technology, Logistics, Supply Chain Management',\n",
       "       'Blockchain, Developer Tools, Enterprise Software',\n",
       "       'Industrial Automation, Logistics, Supply Chain Management',\n",
       "       'Food and Beverage, Food Delivery, Snack Food', 'Education',\n",
       "       'E-Commerce, Fashion, Jewelry, Retail', 'Renewable Energy',\n",
       "       'E-Learning, Education',\n",
       "       'Clean Energy, CleanTech, Laundry and Dry-cleaning',\n",
       "       'E-Commerce, Fashion, Mobile',\n",
       "       'Apps, Messaging, Navigation, Public Safety', 'Transportation',\n",
       "       'Fitness, Health Care, Wellness',\n",
       "       'Artificial Intelligence, Machine Learning, SaaS, Virtual Assistant',\n",
       "       'Hospitality', 'Food and Beverage, Tea',\n",
       "       'Media and Entertainment, News, Outdoors',\n",
       "       'Broadcasting, Media and Entertainment, Music, Music Streaming, Video, Video Streaming',\n",
       "       'B2B, Information Services, Information Technology',\n",
       "       'EdTech, Education, Enterprise Software, Peer to Peer',\n",
       "       'Health Care, Medical', 'E-Commerce',\n",
       "       'Health Care, Hospital, Wellness', '—', 'Sports',\n",
       "       'Big Data, Consumer Lending, FinTech',\n",
       "       'Cloud Computing, Computer, Semiconductor',\n",
       "       'Health Care, Medical, Pharmaceutical', 'Food Processing, Retail',\n",
       "       'Trading Platform', \"Consumer Goods, Lifestyle, Men's\", 'Wellness',\n",
       "       'Food and Beverage, Food Processing, Nutrition', 'Fashion',\n",
       "       'Automotive, Electric Vehicle, Energy Storage',\n",
       "       'Consulting, Retail, Social',\n",
       "       'Biotechnology, Life Science, Pharmaceutical, Product Research',\n",
       "       'Health Care',\n",
       "       'Credit, Financial Services, FinTech, Personal Finance',\n",
       "       'Communities, Coworking, Incubators',\n",
       "       'Consumer, Financial Services, FinTech',\n",
       "       'Consumer Applications, Information Services, Location Based Services, Virtual Assistant',\n",
       "       'Mobile, Mobile Apps, Personalization, Test and Measurement, Web Apps',\n",
       "       'Education, Financial Services, FinTech',\n",
       "       'Advertising, Consulting, Digital Marketing',\n",
       "       'Marketplace, Real Estate, Rental Property',\n",
       "       'E-Learning, Internet, Video Games',\n",
       "       'Artificial Intelligence, Cloud Computing, Video',\n",
       "       'Health Care, Information Technology', 'Aerospace',\n",
       "       'E-Commerce, Fashion, Lifestyle',\n",
       "       'Artificial Intelligence, Business Intelligence, Industrial Automation, Machine Learning',\n",
       "       'Home Decor, Home Improvement, Home Renovation, Home Services, Interior Design, Smart Home',\n",
       "       'EdTech, Education, Information Services, SaaS', 'Energy, Solar',\n",
       "       'B2B, Biometrics, Cyber Security, Fraud Detection, SaaS, Security',\n",
       "       'Artificial Intelligence, Social',\n",
       "       'Logistics, Transportation, Travel',\n",
       "       'Digital Marketing, SEM, SEO, Web Development',\n",
       "       'Health Care, Hospital, Medical', 'Finance, Financial Services',\n",
       "       'Food Delivery, Food Processing, Internet',\n",
       "       'E-Commerce, Food and Beverage, Internet',\n",
       "       'Fitness, Food and Beverage, Health Care, Nutrition',\n",
       "       'EdTech, Education, Knowledge Management',\n",
       "       'Apps, Beauty, Consumer, Retail',\n",
       "       'Creative Agency, Crowdfunding, EdTech, Health Care, Internet, Medical, Non Profit, Personal Health',\n",
       "       'Consumer Lending, Financial Services, FinTech, Insurance, Lending, Mobile Payments, Payments, Wealth Management',\n",
       "       'E-Learning, Education, Higher Education', 'Health Diagnostics',\n",
       "       'EdTech, Education', 'Financial Services, SaaS, Security',\n",
       "       'Banking, Finance, Financial Services, Non Profit',\n",
       "       'B2B, E-Commerce, Mobile',\n",
       "       'Automotive, Electric Vehicle, Renewable Energy', 'E-Learning',\n",
       "       'Embedded Systems, Health Care, Medical, Product Research',\n",
       "       'Apps, E-Commerce, Internet',\n",
       "       'Advertising, Human Resources, Marketing',\n",
       "       'Beauty, Fitness, Home Services, Internet',\n",
       "       'Health Care, Medical Device, Public Safety',\n",
       "       'Food Delivery, Online Portals, Restaurants',\n",
       "       'AgTech, B2B, Supply Chain Management',\n",
       "       'Credit Cards, Finance, Mobile Apps, Mobile Payments, Payments',\n",
       "       'Software',\n",
       "       'EdTech, Education, Higher Education, Secondary Education',\n",
       "       'Manufacturing, Retail', 'Manufacturing',\n",
       "       'Information Services, Information Technology, InsurTech',\n",
       "       'Consumer Lending, FinTech', 'Internet, Social Network, TV',\n",
       "       'Beauty, Health Care', 'Hospital', 'Events',\n",
       "       '3D Printing, Manufacturing, Product Design', 'Automotive',\n",
       "       'Automotive, Retail', 'Apps, Audio', 'Automotive, E-Commerce',\n",
       "       'Digital Entertainment, Fantasy Sports, Sports',\n",
       "       'E-Learning, EdTech, Education',\n",
       "       'Funding Platform, Incubators, Non Profit',\n",
       "       'Hospitality, Hotel, Leisure, Travel',\n",
       "       'Classifieds, Internet, Marketplace, Rental Property',\n",
       "       'Banking, E-Learning, Trading Platform',\n",
       "       'E-Commerce, Mobile, Retail',\n",
       "       'Artificial Intelligence, Information Technology',\n",
       "       'Enterprise Resource Planning (ERP), Information Services, Information Technology, Real Estate',\n",
       "       'Banking, Finance, Financial Services',\n",
       "       'Audio, Mobile, Tourism, Travel',\n",
       "       'Energy, Energy Storage, Infrastructure',\n",
       "       'Government, Information Technology, Software',\n",
       "       'Information Technology',\n",
       "       'Education, Information Technology, Internet, Mobile, Software',\n",
       "       'Consumer Lending, Financial Services, Lending, Personal Finance',\n",
       "       'Digital Media, Internet, Media and Entertainment, Online Portals, Social Media',\n",
       "       'Business Intelligence, Customer Service, Market Research, SaaS',\n",
       "       'Credit, Financial Services, FinTech, Lending',\n",
       "       'Children, Education, Parenting',\n",
       "       'Automotive, Battery, Energy, Energy Storage',\n",
       "       'E-Commerce, Mobile, Sharing Economy',\n",
       "       'Food Delivery, Organic, Organic Food', 'Mobile', 'Rental',\n",
       "       'Travel', 'Consumer', 'B2B, Farming, Marketplace',\n",
       "       'Wealth Management', 'Biotechnology',\n",
       "       'Education, Gaming, Training', 'Veterinary',\n",
       "       'Internet, Mobile, Social Entrepreneurship, Telecommunications, Wireless',\n",
       "       'Health Care, Hospital, Supply Chain Management',\n",
       "       'Tourism, Travel', 'Hospitality, Real Estate', 'Finance',\n",
       "       'Digital Media, EBooks, Publishing, Reading Apps',\n",
       "       'Consumer Electronics, Embedded Systems, Hardware, Smart Building, Software',\n",
       "       'Food and Beverage, Food Processing',\n",
       "       'Internet, Marketplace, Shopping',\n",
       "       'Analytics, Computer Vision, Enterprise Software, Machine Learning, Natural Language Processing, Speech Recognition',\n",
       "       'Facilities Support Services',\n",
       "       'Automotive, Electric Vehicle, Energy',\n",
       "       'Health Care, Health Diagnostics, Predictive Analytics',\n",
       "       'Cloud Computing, Computer, SaaS, Software',\n",
       "       'Fashion, Lifestyle, Retail', 'Medical', 'Music Streaming',\n",
       "       'Finance, Impact Investing, Internet',\n",
       "       'Internet, Social Entrepreneurship', 'Retail',\n",
       "       'Finance, Impact Investing, Mobile Apps',\n",
       "       'Cloud Computing, Computer, Software',\n",
       "       'Business Development, Market Research, Outsourcing',\n",
       "       'Health Care, Hospitality', 'Internet, Social News, Sports',\n",
       "       'Human Resources', 'Finance, Financial Services, FinTech',\n",
       "       'Customer Service, Software, Video, Video Streaming',\n",
       "       'E-Commerce, Food Processing', 'Training',\n",
       "       'Dietary Supplements, Food and Beverage, Health Care, Organic Food, Snack Food',\n",
       "       'Manufacturing, Oil and Gas, Robotics',\n",
       "       'Artificial Intelligence, Computer, Machine Learning',\n",
       "       'Collaboration, Communities, Coworking, Sharing Economy',\n",
       "       'Big Data, EdTech, Machine Learning', 'Nanotechnology',\n",
       "       'Analytics, Audio, Digital Media, Innovation Management, Internet Radio, Media and Entertainment',\n",
       "       'Financial Services, Lending, Peer to Peer',\n",
       "       'E-Commerce, Furniture, Home Decor, Interior Design, Internet',\n",
       "       'Digital Media', 'File Sharing, Personalization, Social Media',\n",
       "       'Home Decor, Interior Design',\n",
       "       'Health Care, Medical Device, Mobile Apps',\n",
       "       'E-Commerce, Facilities Support Services, Procurement, Supply Chain Management',\n",
       "       'Crowdfunding, Finance, Financial Services',\n",
       "       'Finance, Financial Services, Insurance',\n",
       "       'Children, Education, Online Portals', 'Software, Virtual Reality',\n",
       "       'B2B, Food and Beverage, Food Delivery',\n",
       "       'Catering, Food and Beverage, Food Delivery, Food Processing',\n",
       "       'Food and Beverage, Snack Food', 'Automotive, E-Commerce, Mobile',\n",
       "       'Computer, Digital Marketing, Facilities Support Services, Graphic Design, Internet, Mobile Apps, Social Media Marketing, Web Development',\n",
       "       'Android, Big Data, Blockchain, Cloud Computing, EdTech, Education, Information Technology, iOS, Training, Web Development',\n",
       "       'Analytics, CRM, Loyalty Programs, Machine Learning, Marketing Automation, Retail Technology, SaaS, Small and Medium Businesses',\n",
       "       'Delivery, Information Technology, Mobile Apps',\n",
       "       'Environmental Consulting, Renewable Energy',\n",
       "       'Big Data, Business Intelligence, Financial Services, FinTech, Personal Finance',\n",
       "       'Commercial Real Estate, Coworking, Office Administration, Real Estate',\n",
       "       'Food and Beverage, Food Processing, Organic Food, Snack Food',\n",
       "       'Apps, Health Care, Internet, Mobile Apps, Personal Health',\n",
       "       'Digital Media, Incubators, Social Entrepreneurship',\n",
       "       'Finance, Financial Services, Marketing',\n",
       "       'Biotechnology, Health Care, Life Science, Medical Device',\n",
       "       'Education, Human Resources', 'Consumer Electronics',\n",
       "       'Apps, Health Care, Hospital, Mobile Apps',\n",
       "       'Delivery Service, Logistics, Service Industry',\n",
       "       'Big Data, Data Visualization, Logistics, Software',\n",
       "       'Basketball, Cricket, Cycling, eSports, Fitness, Golf, Health Care, Hockey, Sports, Swimming, Table Tennis, Volley Ball',\n",
       "       'Media and Entertainment, News, Publishing', 'Consulting',\n",
       "       'Big Data, Financial Services, Machine Learning, Predictive Analytics',\n",
       "       'Agriculture, AgTech, Manufacturing',\n",
       "       'Digital Media, News, Publishing', 'Health Care, Hospital',\n",
       "       'B2B, E-Commerce, Enterprise',\n",
       "       'Fraud Detection, Information Services, Security',\n",
       "       'Agriculture, AgTech, Artificial Intelligence, Internet of Things, Machine Learning',\n",
       "       'Cryptocurrency, Trading Platform',\n",
       "       'Finance, FinTech, Mobile Payments', 'Wedding',\n",
       "       'E-Learning, EdTech, Education, Image Recognition, Machine Learning, STEM Education',\n",
       "       'Consumer Goods', 'Digital Entertainment',\n",
       "       'Crowdsourcing, Financial Services, Funding Platform, Venture Capital',\n",
       "       'Delivery, Drones, Geospatial, Robotics',\n",
       "       'Health Care, Information Technology, Management Information Systems',\n",
       "       'Farming',\n",
       "       'Business Travel, Hospitality, Hotel, Marketplace, Tourism, Travel Accommodations',\n",
       "       'Career Planning, Education, Higher Education, Service Industry',\n",
       "       'Medical Device', 'Alternative Medicine, Health Care',\n",
       "       'Internet, Software',\n",
       "       'Dental, Elder Care, Health Care, Home Health Care, Personal Health',\n",
       "       'Financial Services, Insurance, Private Social Networking',\n",
       "       'Consumer Electronics, E-Commerce, E-Commerce Platforms, Electronics, Shipping, Shopping',\n",
       "       'CleanTech', 'Advertising, Internet, Marketing',\n",
       "       'Human Resources, Security, Training',\n",
       "       'Consumer Lending, Finance, FinTech',\n",
       "       'Marketing, Social Media, Video', 'Banking', 'Food Processing',\n",
       "       'Apps', 'Marketing',\n",
       "       'Apps, B2B, Freight Service, Logistics, SaaS, Shipping, Supply Chain Management, Transportation',\n",
       "       'Digital Entertainment, Fantasy Sports, Gaming, Sports',\n",
       "       'Automotive, Last Mile Transportation, Peer to Peer, Ride Sharing',\n",
       "       'Commercial, E-Learning, Education',\n",
       "       'Continuing Education, EdTech, Education, Skill Assessment',\n",
       "       'Smart Cities, Telecommunications', 'Internet of Things, Robotics',\n",
       "       'Apps, Home Services, Information Services, Information Technology',\n",
       "       'Medical, Tourism', 'Career Planning, Education, Internet',\n",
       "       'Fashion, Graphic Design, Wearables',\n",
       "       'Communities, Leisure, Mobile Apps, Software',\n",
       "       'Automotive, Rental, Sharing Economy',\n",
       "       'Energy, Environmental Consulting, Renewable Energy, Solar',\n",
       "       'Information Technology, SaaS, Security',\n",
       "       'Crowdfunding, Financial Services, Internet',\n",
       "       'Customer Service, Information Technology, Internet, Sales Automation',\n",
       "       'Advertising, Artificial Intelligence, Digital Media, iOS, Location Based Services, News, Video, Video on Demand, Video Streaming',\n",
       "       'Credit Cards, Payments, Property Insurance, Property Management, Rental Property',\n",
       "       'Beauty, Cosmetics, Health Care, Service Industry',\n",
       "       'EdTech, Education, Mobile, Tutoring', 'Social Media, Sports',\n",
       "       'Biopharma', 'E-Commerce, E-Commerce Platforms, Retail',\n",
       "       'E-Commerce, Fashion, Shopping',\n",
       "       'Digital Entertainment, Mobile, PC Games',\n",
       "       'Finance, Financial Services, Small and Medium Businesses',\n",
       "       'Artificial Intelligence, Energy, Oil and Gas',\n",
       "       'Computer, FinTech, Risk Management, Software',\n",
       "       'Apps, Financial Services, FinTech',\n",
       "       \"Child Care, Health Care, Hospital, Medical, Women's\",\n",
       "       'Agriculture, Mobile',\n",
       "       'Finance, FinTech, Payments, Property Development, Rental',\n",
       "       'Information Services, Information Technology, Mobile, Software',\n",
       "       'Apps, Fitness, Health Care, mHealth',\n",
       "       'Food and Beverage, Food Delivery', 'Apps, Payments, Retail',\n",
       "       'Health Insurance, Insurance, Life Insurance',\n",
       "       'Rental, Taxi Service, Travel',\n",
       "       'E-Commerce, E-Commerce Platforms, Internet, Retail',\n",
       "       'Financial Services, Professional Services',\n",
       "       'Customer Service, Messaging, Mobile Apps, Personalization',\n",
       "       'Gaming, iOS, Sports',\n",
       "       'E-Commerce, E-Commerce Platforms, Internet, Mobile Apps, Social Media',\n",
       "       'Search Engine',\n",
       "       'Battery, Electric Vehicle, Energy, Renewable Energy, Transportation',\n",
       "       'Agriculture, Farmers Market, Farming',\n",
       "       'Artificial Intelligence, Drones, Navigation, Packaging Services, Robotics',\n",
       "       'Fitness, GreenTech, Internet of Things, Mobile Apps, Ride Sharing, Transportation',\n",
       "       'Mobile, Software, Travel', 'Cosmetics',\n",
       "       'Consulting, Cyber Security, Network Security',\n",
       "       'eSports, Gaming, Video Games', 'Fashion, Jewelry',\n",
       "       'B2B, Medical Device', 'Consumer Goods, Manufacturing',\n",
       "       'Biotechnology, Health Care, Wellness',\n",
       "       'Health Care, Hospital, Medical, Robotics',\n",
       "       'E-Commerce, Fitness, Health Care',\n",
       "       'Financial Services, Venture Capital', 'Accounting, Apps, FinTech',\n",
       "       'Apps, Mobile, Transportation', 'Reading Apps',\n",
       "       'Energy, Renewable Energy, Solar',\n",
       "       'Banking, Financial Services, FinTech', 'Apps, Education, Retail',\n",
       "       'Electric Vehicle',\n",
       "       'Automotive, Battery, Electric Vehicle, Manufacturing, Mechanical Design',\n",
       "       'Automotive, E-Commerce, Marketplace', 'Agriculture',\n",
       "       'Apps, Information Services, Information Technology',\n",
       "       'B2B, Marketplace', 'Packaging Services',\n",
       "       'Computer, Furniture, Software',\n",
       "       'Food Delivery, Hospitality, Reservations, Restaurants, Search Engine',\n",
       "       'Collaboration, Communities, Coworking, Real Estate',\n",
       "       'Accounting, Banking, Finance',\n",
       "       'Cloud Computing, Enterprise Software, Network Hardware, Network Security, SaaS',\n",
       "       'Information Services, Internet, Logistics, Supply Chain Management, Transportation',\n",
       "       'Automotive, E-Commerce, Information Services',\n",
       "       'Delivery, Logistics, Transportation',\n",
       "       'Automotive, E-Commerce Platforms, Marketplace',\n",
       "       'Last Mile Transportation, Railroad, Transportation, Travel',\n",
       "       'Cooking, E-Commerce, Food and Beverage, Food Delivery, Online Portals',\n",
       "       'FinTech, Mobile, Mobile Payments, Payments, Retail Technology',\n",
       "       'Online Games, Software',\n",
       "       'Online Portals, Property Management, Rental',\n",
       "       'E-Commerce, Food and Beverage, Tea',\n",
       "       'Music, Social Network, Video',\n",
       "       'Health Care, Pharmaceutical, Wellness',\n",
       "       'Delivery Service, Food and Beverage, Food Delivery',\n",
       "       'Hospitality, Information Technology, Travel Accommodations',\n",
       "       'Biotechnology, Diabetes, Health Care',\n",
       "       'Autonomous Vehicles, Last Mile Transportation, Recreational Vehicles, Rental',\n",
       "       'Finance, Financial Exchanges, Financial Services, Micro Lending',\n",
       "       'Analytics, Apps, Market Research',\n",
       "       'E-Commerce, E-Commerce Platforms, Furniture, Home Decor, Internet',\n",
       "       'Apps, Mobile, Mobile Apps, Software',\n",
       "       'News, Publishing, Social Media',\n",
       "       'Industrial, Industrial Automation',\n",
       "       'Internet, Mobile Apps, Social Network',\n",
       "       'Health Care, Health Diagnostics, Internet of Things, Life Science, Machine Learning, Medical, Medical Device',\n",
       "       'E-Commerce, Furniture, Interior Design', 'Apps, Events, News',\n",
       "       'Artificial Intelligence, Human Resources, Information Services, Information Technology',\n",
       "       'Logistics, Railroad, Transportation',\n",
       "       'Dating, Private Social Networking',\n",
       "       'Artificial Intelligence, Machine Learning, PaaS',\n",
       "       'Consumer, Furniture, Home Decor, Home Improvement',\n",
       "       'Apps, E-Commerce, Internet, Mobile, Ride Sharing, Transportation',\n",
       "       'Health Care, Health Insurance', 'Energy, Natural Resources',\n",
       "       'E-Commerce, Education, Health Care',\n",
       "       'Apps, Health Care, Pharmaceutical',\n",
       "       'Internet, Knowledge Management',\n",
       "       'Credit, Finance, FinTech, Lending, Sales Automation',\n",
       "       'Banking, Financial Services, Internet',\n",
       "       'E-Commerce, Health Care, Retail',\n",
       "       'Child Care, Information Technology',\n",
       "       'Financial Services, Micro Lending',\n",
       "       'E-Commerce, Retail, Shopping',\n",
       "       'Food and Beverage, Snack Food, Tea',\n",
       "       'Delivery Service, E-Commerce, Logistics',\n",
       "       'Fashion, Lifestyle, Rental', 'Fantasy Sports, Mobile, Sports',\n",
       "       'Beauty, Fashion, Wellness', 'Food and Beverage, Restaurants, Tea',\n",
       "       'Fitness, Sporting Goods, Sports',\n",
       "       'Food and Beverage, Food Processing, Manufacturing',\n",
       "       'E-Learning, Internet', 'Eyewear, Internet',\n",
       "       'Information Technology, Mobile, News, Operating Systems, Social Media, Social News',\n",
       "       'FinTech, Internet, Payments, Service Industry',\n",
       "       'B2B, Business Development, Internet, Marketplace',\n",
       "       'Food and Beverage, Food Delivery, Internet',\n",
       "       'Biotechnology, Health Care, Pharmaceutical', 'Ecommerce',\n",
       "       'Edtech', 'Interior design', 'AgriTech', 'Technology', 'SaaS',\n",
       "       'AI & Tech', 'E-commerce', 'E-commerce & AR', 'Fintech', 'HR tech',\n",
       "       'Food tech', 'Health', 'Healthcare', 'Safety tech',\n",
       "       'Pharmaceutical', 'Insurance technology', 'AI', 'Foodtech', 'Food',\n",
       "       'IoT', 'E-marketplace', 'Robotics & AI', 'Logistics',\n",
       "       'Food & Nutrition', 'Social Media', nan, 'E-Sports', 'B2B',\n",
       "       'Jewellery', 'B2B Supply Chain', 'Games', 'Food & tech',\n",
       "       'Accomodation', 'Automotive tech', 'Legal tech', 'Mutual Funds',\n",
       "       'Cybersecurity', 'Automobile', 'Healthtech', 'Yoga & wellness',\n",
       "       'Virtual Banking', 'Transport & Rentals',\n",
       "       'Marketing & Customer loyalty', 'Infratech',\n",
       "       'Automobile & Technology', 'EdTech', 'Hygiene management',\n",
       "       'Escrow', 'Networking platform', 'FinTech', 'Crowdsourcing',\n",
       "       'Food & Bevarages', 'HealthTech', 'Fashion startup',\n",
       "       'Food Industry', 'Virtual auditing startup', 'Gaming',\n",
       "       'Work fulfillment', 'AI startup', 'Telecommunication',\n",
       "       'Tech Startup', 'Medtech', 'Tyre management', 'Cloud company',\n",
       "       'Software company', 'Venture capitalist', 'Renewable player',\n",
       "       'IoT startup', 'SaaS startup', 'Aero company', 'Marketing company',\n",
       "       'Retail startup', 'Co-working Startup', 'Finance company',\n",
       "       'Tech company', 'Solar Monitoring Company',\n",
       "       'Video sharing platform', 'Gaming startup',\n",
       "       'Video streaming platform', 'Consumer appliances',\n",
       "       'Blockchain startup', 'Conversational AI platform', 'Real Estate',\n",
       "       'SaaS platform', 'AI platform', 'Fusion beverages', 'HR Tech',\n",
       "       'Job portal', 'Dairy startup', 'Content management', 'Spacetech',\n",
       "       'Trading platform', 'AI Company', 'Photonics startup',\n",
       "       'Entertainment', 'Scanning app', 'Skincare startup',\n",
       "       'Food and Beverages', 'Biotechnology company', 'FoodTech',\n",
       "       'Proptech', 'Fitness startup', 'PaaS startup', 'Beverages',\n",
       "       'Automobiles', 'Deeptech', 'EV startup', 'AR/VR startup',\n",
       "       'Recruitment startup', 'QSR startup', 'Video platform',\n",
       "       'Fertility tech', 'Luxury car startup', 'FM', 'Nutrition sector',\n",
       "       'Tech platform', 'Video', 'Retail Tech', 'HeathTech',\n",
       "       'Sles and marketing', 'LegalTech', 'Car Service',\n",
       "       'Bike marketplace', 'Agri tech', 'Reatil startup', 'AR platform',\n",
       "       'Content marketplace', 'Interior Design', 'Rental space',\n",
       "       'Soil-Tech', 'Ayurveda tech', 'Packaging solution startup',\n",
       "       'Cleantech', 'Sanitation solutions', 'HealthCare', 'Home Design',\n",
       "       'InsureTech', 'AI Startup', 'Solar solution', 'Jewellery startup',\n",
       "       'Multinational conglomerate company', 'Deeptech startup',\n",
       "       'Social Network', 'Publication', 'Tech', 'Venture capital',\n",
       "       'Entreprenurship', 'Food devlivery', 'Warehouse',\n",
       "       'Online financial service', 'Eyeglasses', 'Battery design',\n",
       "       'Online credit management startup', 'Beverage', 'TravelTech',\n",
       "       'Startup laboratory', 'Personal care startup',\n",
       "       'Customer service company', 'SaaS\\xa0\\xa0startup',\n",
       "       'Marketing startup', 'Service industry', 'Social media',\n",
       "       'AR startup', 'HR Tech startup', 'Automotive Startup',\n",
       "       'Food Startup', 'EdTech Startup', 'Car Trade', 'EdtTech',\n",
       "       'AI Platform', 'Automation', 'Solar SaaS', 'WL & RAC protection',\n",
       "       'Social commerce', 'Home interior services', 'Agritech startup',\n",
       "       'API platform', 'Deep Tech', 'Electricity', 'Automotive company',\n",
       "       'FMCG', 'Insurance Tech', 'Video personalization',\n",
       "       'Software Company', 'Biomaterial startup', 'IT', 'Craft Beer',\n",
       "       'Investment', 'Linguistic Spiritual', 'Construction',\n",
       "       'Battery manufacturer', 'Nano Distribution Network', 'AI health',\n",
       "       'Dating app', 'Media', 'Healthcare/Edtech', 'Social Commerce',\n",
       "       'Agritech/Commerce', 'Mobility tech', 'Social e-commerce',\n",
       "       'Food & Logistics', 'SpaceTech', 'Nutrition Tech', 'HR', None,\n",
       "       'Agritech', 'AR/VR', 'Appliance', 'Mental Health',\n",
       "       'Solar Solution', 'B2B marketplace', 'Fashion Tech',\n",
       "       'Nutrition tech', 'Health & Wellness', 'Cloud Kitchen',\n",
       "       'IoT/Automobile', 'Eye Wear', 'Digital tech', 'Data Intelligence',\n",
       "       'Co-living', 'Food & Beverages', 'Defense tech', 'Marketplace',\n",
       "       'Construction tech', 'Nutrition', 'Coworking', 'Micro-mobiity',\n",
       "       'Auto-tech', 'Beauty', 'Robotics', 'Logitech', 'Med Tech',\n",
       "       'Life sciences', 'Retail Aggregator', 'Deep Tech AI', 'Biotech',\n",
       "       'Blockchain', 'HrTech', 'Mobility/Transport', 'AI & Debt',\n",
       "       'SaaS/Edtech', 'Transport', 'Co-working', 'Insurtech',\n",
       "       'Cryptocurrency', 'Legal', 'Fitness', 'EV',\n",
       "       'Supply chain, Agritech', 'Pharma', 'Foodtech & Logistics',\n",
       "       'Housing', 'Data Analytics', 'Investment Tech', 'Dairy',\n",
       "       'Beauty & wellness', 'Travel & SaaS', 'Tourism & EV', 'Media Tech',\n",
       "       'Location Analytics', 'E store', 'Data Science',\n",
       "       'Health and Fitness', 'Interior & decor', 'eMobility',\n",
       "       'Automation tech', 'Media & Networking', 'E-market',\n",
       "       'AI & Data science', 'Travel tech', 'Automotive and Rentals',\n",
       "       'E-tail', 'AI & Media', 'Machine Learning', 'Content Marktplace',\n",
       "       'Visual Media', 'Hygiene', 'VR & SaaS', 'Sales & Services',\n",
       "       'AI & Deep learning', 'Housing & Rentals', 'Estore', 'E tailor',\n",
       "       'E-mobility', 'Ad-tech', 'Neo-banking', 'Transport Automation',\n",
       "       'Techonology', 'AI Robotics', 'Preschool Daycare', 'Food diet',\n",
       "       'B2B Agritech', 'E-connect', 'Tech hub', 'Consultancy', 'Pharmacy',\n",
       "       'Deisgning', 'Taxation', 'Automobile Technology', 'B2B E-commerce',\n",
       "       'Home services', 'B2B service', 'Helathcare', 'Electronics',\n",
       "       'IT startup', 'Aeorspace', 'Dating', 'Oil and Energy',\n",
       "       'Telecommuncation', 'Milk startup', 'AI Chatbot', 'Food delivery',\n",
       "       'Fantasy sports', 'Video communication', 'Skill development',\n",
       "       'Recruitment', 'Computer Games', 'Apparel & Fashion',\n",
       "       'Logistics & Supply Chain', 'SportsTech', 'HRTech',\n",
       "       'Wine & Spirits', 'Mechanical & Industrial Engineering',\n",
       "       'Spiritual', 'Lifestyle', 'Computer software', 'Tech startup',\n",
       "       'Digital mortgage', 'Information Technology & Services',\n",
       "       'Furniture', 'Healtcare', 'Tobacco', 'Insuretech',\n",
       "       'MLOps platform', 'Venture Capital', 'Pet care', 'Drone',\n",
       "       'Wholesale', 'E-learning', 'Consumer Services',\n",
       "       'Venture Capital & Private Equity', 'Health, Wellness & Fitness',\n",
       "       'OTT', 'Education Management', 'Computer Software',\n",
       "       'Software Startup', 'Computer & Network Security',\n",
       "       'Capital Markets', 'Social network', 'Hospital & Health Care',\n",
       "       'Music', 'Pharmaceuticals', 'None', 'Mobility', 'Digital platform',\n",
       "       'B2B Ecommerce', 'Online Media', 'Mobile Games', 'Food Production',\n",
       "       'Podcast', 'Battery', 'Content publishing', 'Water purification',\n",
       "       'Content commerce', 'Innovation Management',\n",
       "       'Celebrity Engagement', 'Personal Care', 'Cannabis startup',\n",
       "       'Blogging', 'BioTechnology', 'B2B Marketplace', 'Health care',\n",
       "       'Social audio', 'Fashion and lifestyle', 'Delivery service',\n",
       "       'B2B Manufacturing', 'Home Decor', 'Solar', 'TaaS startup',\n",
       "       'Manufacturing startup', 'Vehicle repair startup', 'Advisory firm',\n",
       "       'Legaltech', 'Pollution control equiptment', 'Fashion & Lifestyle',\n",
       "       'D2C', 'Environmental Services', 'Merchandise',\n",
       "       'Facilities Services', 'Marketing & Advertising', 'Eyewear',\n",
       "       'D2C Business', 'NFT Marketplace', 'Consumer software',\n",
       "       'Social community', 'Fishery', 'Renewables & Environment',\n",
       "       'Online storytelling', 'Aviation', 'IT company',\n",
       "       'Environmental service', 'Job discovery platform', 'D2C Fashion',\n",
       "       'Heathcare', 'CRM', 'D2C startup', 'Innovation management',\n",
       "       'Community platform', 'Networking', 'Commercial Real Estate',\n",
       "       'Consumer service', 'Consumer goods', 'MarTech', 'Advertisement',\n",
       "       'Content creation', 'Augmented reality', 'Bike Rental',\n",
       "       'Beauty products', 'Tourism', 'FemTech', 'Cultural',\n",
       "       'Supply chain platform', 'Social platform', 'Real estate',\n",
       "       'AI company', 'Sports startup', 'Matrimony', 'Crypto', 'Clothing',\n",
       "       'Analytics', 'IoT platform', 'Commerce', 'Defense & Space',\n",
       "       'Business Supplies & Equipment', 'NFT', 'Oil & Energy',\n",
       "       'Company-as-a-Service', 'Textiles',\n",
       "       'Professional Training & Coaching', 'Maritime',\n",
       "       'Housing Marketplace', 'Furniture Rental', 'Telecommunications',\n",
       "       'Equity Management', 'Cloud kitchen', 'Community',\n",
       "       'Higher Education', 'Mechanical Or Industrial Engineering',\n",
       "       'D2C jewellery', 'Sales and Distribution', 'Information Services',\n",
       "       'Translation & Localization', 'Investment Banking', 'Femtech',\n",
       "       'sports', 'Foootwear', 'Legal Services', 'Arts & Crafts',\n",
       "       'Investment Management', 'Management Consulting', 'B2B startup',\n",
       "       'Design', 'B2B Travel', 'Product studio', 'Aviation & Aerospace',\n",
       "       'Staffing & Recruiting'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the unique values in location and inconsistencies\n",
    "merged_df['industry'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Fintech                                               257\n",
       "Edtech                                                215\n",
       "Financial services                                     75\n",
       "E-commerce                                             75\n",
       "Healthcare                                             67\n",
       "                                                     ... \n",
       "Health insurance, insurance, life insurance             1\n",
       "Rental, taxi service, travel                            1\n",
       "E-commerce, e-commerce platforms, internet, retail      1\n",
       "Financial services, professional services               1\n",
       "Staffing & recruiting                                   1\n",
       "Name: count, Length: 832, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['industry'] = merged_df['industry'].str.capitalize()\n",
    "merged_df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Brand marketing', 'Agriculture', 'Credit', 'Financial services',\n",
       "       'E-commerce platforms', 'Cloud infrastructure', 'Internet',\n",
       "       'Market research', 'Information services', 'Mobile payments',\n",
       "       'B2b', 'Apps', 'Food delivery', 'Industrial automation',\n",
       "       'Automotive', 'Finance', 'Accounting', 'Artificial intelligence',\n",
       "       'Internet of things', 'Air transportation', 'Food and beverage',\n",
       "       'Autonomous vehicles', 'Enterprise software', 'Logistics',\n",
       "       'Insurance', 'Information technology', 'Blockchain', 'Education',\n",
       "       'E-commerce', 'Renewable energy', 'E-learning', 'Clean energy',\n",
       "       'Transportation', 'Fitness', 'Hospitality',\n",
       "       'Media and entertainment', 'Broadcasting', 'Edtech', 'Health care',\n",
       "       '—', 'Sports', 'Big data', 'Cloud computing', 'Food processing',\n",
       "       'Trading platform', 'Consumer goods', 'Wellness', 'Fashion',\n",
       "       'Consulting', 'Biotechnology', 'Communities', 'Consumer',\n",
       "       'Consumer applications', 'Mobile', 'Advertising', 'Marketplace',\n",
       "       'Aerospace', 'Home decor', 'Energy', 'Digital marketing',\n",
       "       'Creative agency', 'Consumer lending', 'Health diagnostics',\n",
       "       'Banking', 'Embedded systems', 'Beauty', 'Agtech', 'Credit cards',\n",
       "       'Software', 'Manufacturing', 'Hospital', 'Events', '3d printing',\n",
       "       'Digital entertainment', 'Funding platform', 'Classifieds',\n",
       "       'Enterprise resource planning (erp)', 'Audio', 'Government',\n",
       "       'Digital media', 'Business intelligence', 'Children', 'Rental',\n",
       "       'Travel', 'Wealth management', 'Veterinary', 'Tourism',\n",
       "       'Consumer electronics', 'Analytics', 'Facilities support services',\n",
       "       'Medical', 'Music streaming', 'Retail', 'Business development',\n",
       "       'Human resources', 'Customer service', 'Training',\n",
       "       'Dietary supplements', 'Collaboration', 'Nanotechnology',\n",
       "       'File sharing', 'Crowdfunding', 'Catering', 'Computer', 'Android',\n",
       "       'Delivery', 'Environmental consulting', 'Commercial real estate',\n",
       "       'Delivery service', 'Basketball', 'Fraud detection',\n",
       "       'Cryptocurrency', 'Wedding', 'Crowdsourcing', 'Farming',\n",
       "       'Business travel', 'Career planning', 'Medical device',\n",
       "       'Alternative medicine', 'Dental', 'Cleantech', 'Marketing',\n",
       "       'Commercial', 'Continuing education', 'Smart cities',\n",
       "       'Social media', 'Biopharma', 'Child care', 'Health insurance',\n",
       "       'Gaming', 'Search engine', 'Battery', 'Cosmetics', 'Esports',\n",
       "       'Reading apps', 'Electric vehicle', 'Packaging services',\n",
       "       'Last mile transportation', 'Cooking', 'Fintech', 'Online games',\n",
       "       'Online portals', 'Music', 'News', 'Industrial', 'Dating',\n",
       "       'Fantasy sports', 'Eyewear', 'Ecommerce', 'Interior design',\n",
       "       'Agritech', 'Technology', 'Saas', 'Ai & tech', 'E-commerce & ar',\n",
       "       'Hr tech', 'Food tech', 'Health', 'Healthcare', 'Safety tech',\n",
       "       'Pharmaceutical', 'Insurance technology', 'Ai', 'Foodtech', 'Food',\n",
       "       'Iot', 'E-marketplace', 'Robotics & ai', 'Food & nutrition', 'nan',\n",
       "       'E-sports', 'Jewellery', 'B2b supply chain', 'Games',\n",
       "       'Food & tech', 'Accomodation', 'Automotive tech', 'Legal tech',\n",
       "       'Mutual funds', 'Cybersecurity', 'Automobile', 'Healthtech',\n",
       "       'Yoga & wellness', 'Virtual banking', 'Transport & rentals',\n",
       "       'Marketing & customer loyalty', 'Infratech',\n",
       "       'Automobile & technology', 'Hygiene management', 'Escrow',\n",
       "       'Networking platform', 'Food & bevarages', 'Fashion startup',\n",
       "       'Food industry', 'Virtual auditing startup', 'Work fulfillment',\n",
       "       'Ai startup', 'Telecommunication', 'Tech startup', 'Medtech',\n",
       "       'Tyre management', 'Cloud company', 'Software company',\n",
       "       'Venture capitalist', 'Renewable player', 'Iot startup',\n",
       "       'Saas startup', 'Aero company', 'Marketing company',\n",
       "       'Retail startup', 'Co-working startup', 'Finance company',\n",
       "       'Tech company', 'Solar monitoring company',\n",
       "       'Video sharing platform', 'Gaming startup',\n",
       "       'Video streaming platform', 'Consumer appliances',\n",
       "       'Blockchain startup', 'Conversational ai platform', 'Real estate',\n",
       "       'Saas platform', 'Ai platform', 'Fusion beverages', 'Job portal',\n",
       "       'Dairy startup', 'Content management', 'Spacetech', 'Ai company',\n",
       "       'Photonics startup', 'Entertainment', 'Scanning app',\n",
       "       'Skincare startup', 'Food and beverages', 'Biotechnology company',\n",
       "       'Proptech', 'Fitness startup', 'Paas startup', 'Beverages',\n",
       "       'Automobiles', 'Deeptech', 'Ev startup', 'Ar/vr startup',\n",
       "       'Recruitment startup', 'Qsr startup', 'Video platform',\n",
       "       'Fertility tech', 'Luxury car startup', 'Fm', 'Nutrition sector',\n",
       "       'Tech platform', 'Video', 'Retail tech', 'Heathtech',\n",
       "       'Sles and marketing', 'Legaltech', 'Car service',\n",
       "       'Bike marketplace', 'Agri tech', 'Reatil startup', 'Ar platform',\n",
       "       'Content marketplace', 'Rental space', 'Soil-tech',\n",
       "       'Ayurveda tech', 'Packaging solution startup',\n",
       "       'Sanitation solutions', 'Home design', 'Insuretech',\n",
       "       'Solar solution', 'Jewellery startup',\n",
       "       'Multinational conglomerate company', 'Deeptech startup',\n",
       "       'Social network', 'Publication', 'Tech', 'Venture capital',\n",
       "       'Entreprenurship', 'Food devlivery', 'Warehouse',\n",
       "       'Online financial service', 'Eyeglasses', 'Battery design',\n",
       "       'Online credit management startup', 'Beverage', 'Traveltech',\n",
       "       'Startup laboratory', 'Personal care startup',\n",
       "       'Customer service company', 'Saas\\xa0\\xa0startup',\n",
       "       'Marketing startup', 'Service industry', 'Ar startup',\n",
       "       'Hr tech startup', 'Automotive startup', 'Food startup',\n",
       "       'Edtech startup', 'Car trade', 'Edttech', 'Automation',\n",
       "       'Solar saas', 'Wl & rac protection', 'Social commerce',\n",
       "       'Home interior services', 'Agritech startup', 'Api platform',\n",
       "       'Deep tech', 'Electricity', 'Automotive company', 'Fmcg',\n",
       "       'Insurance tech', 'Video personalization', 'Biomaterial startup',\n",
       "       'It', 'Craft beer', 'Investment', 'Linguistic spiritual',\n",
       "       'Construction', 'Battery manufacturer',\n",
       "       'Nano distribution network', 'Ai health', 'Dating app', 'Media',\n",
       "       'Healthcare/edtech', 'Agritech/commerce', 'Mobility tech',\n",
       "       'Social e-commerce', 'Food & logistics', 'Nutrition tech', 'Hr',\n",
       "       'None', 'Ar/vr', 'Appliance', 'Mental health', 'B2b marketplace',\n",
       "       'Fashion tech', 'Health & wellness', 'Cloud kitchen',\n",
       "       'Iot/automobile', 'Eye wear', 'Digital tech', 'Data intelligence',\n",
       "       'Co-living', 'Food & beverages', 'Defense tech',\n",
       "       'Construction tech', 'Nutrition', 'Coworking', 'Micro-mobiity',\n",
       "       'Auto-tech', 'Robotics', 'Logitech', 'Med tech', 'Life sciences',\n",
       "       'Retail aggregator', 'Deep tech ai', 'Biotech', 'Hrtech',\n",
       "       'Mobility/transport', 'Ai & debt', 'Saas/edtech', 'Transport',\n",
       "       'Co-working', 'Insurtech', 'Legal', 'Ev', 'Supply chain', 'Pharma',\n",
       "       'Foodtech & logistics', 'Housing', 'Data analytics',\n",
       "       'Investment tech', 'Dairy', 'Beauty & wellness', 'Travel & saas',\n",
       "       'Tourism & ev', 'Media tech', 'Location analytics', 'E store',\n",
       "       'Data science', 'Health and fitness', 'Interior & decor',\n",
       "       'Emobility', 'Automation tech', 'Media & networking', 'E-market',\n",
       "       'Ai & data science', 'Travel tech', 'Automotive and rentals',\n",
       "       'E-tail', 'Ai & media', 'Machine learning', 'Content marktplace',\n",
       "       'Visual media', 'Hygiene', 'Vr & saas', 'Sales & services',\n",
       "       'Ai & deep learning', 'Housing & rentals', 'Estore', 'E tailor',\n",
       "       'E-mobility', 'Ad-tech', 'Neo-banking', 'Transport automation',\n",
       "       'Techonology', 'Ai robotics', 'Preschool daycare', 'Food diet',\n",
       "       'B2b agritech', 'E-connect', 'Tech hub', 'Consultancy', 'Pharmacy',\n",
       "       'Deisgning', 'Taxation', 'Automobile technology', 'B2b e-commerce',\n",
       "       'Home services', 'B2b service', 'Helathcare', 'Electronics',\n",
       "       'It startup', 'Aeorspace', 'Oil and energy', 'Telecommuncation',\n",
       "       'Milk startup', 'Ai chatbot', 'Video communication',\n",
       "       'Skill development', 'Recruitment', 'Computer games',\n",
       "       'Apparel & fashion', 'Logistics & supply chain', 'Sportstech',\n",
       "       'Wine & spirits', 'Mechanical & industrial engineering',\n",
       "       'Spiritual', 'Lifestyle', 'Computer software', 'Digital mortgage',\n",
       "       'Information technology & services', 'Furniture', 'Healtcare',\n",
       "       'Tobacco', 'Mlops platform', 'Pet care', 'Drone', 'Wholesale',\n",
       "       'Consumer services', 'Venture capital & private equity', 'Ott',\n",
       "       'Education management', 'Software startup',\n",
       "       'Computer & network security', 'Capital markets',\n",
       "       'Hospital & health care', 'Pharmaceuticals', 'Mobility',\n",
       "       'Digital platform', 'B2b ecommerce', 'Online media',\n",
       "       'Mobile games', 'Food production', 'Podcast', 'Content publishing',\n",
       "       'Water purification', 'Content commerce', 'Innovation management',\n",
       "       'Celebrity engagement', 'Personal care', 'Cannabis startup',\n",
       "       'Blogging', 'Social audio', 'Fashion and lifestyle',\n",
       "       'B2b manufacturing', 'Solar', 'Taas startup',\n",
       "       'Manufacturing startup', 'Vehicle repair startup', 'Advisory firm',\n",
       "       'Pollution control equiptment', 'Fashion & lifestyle', 'D2c',\n",
       "       'Environmental services', 'Merchandise', 'Facilities services',\n",
       "       'Marketing & advertising', 'D2c business', 'Nft marketplace',\n",
       "       'Consumer software', 'Social community', 'Fishery',\n",
       "       'Renewables & environment', 'Online storytelling', 'Aviation',\n",
       "       'It company', 'Environmental service', 'Job discovery platform',\n",
       "       'D2c fashion', 'Heathcare', 'Crm', 'D2c startup',\n",
       "       'Community platform', 'Networking', 'Consumer service', 'Martech',\n",
       "       'Advertisement', 'Content creation', 'Augmented reality',\n",
       "       'Bike rental', 'Beauty products', 'Femtech', 'Cultural',\n",
       "       'Supply chain platform', 'Social platform', 'Sports startup',\n",
       "       'Matrimony', 'Crypto', 'Clothing', 'Iot platform', 'Commerce',\n",
       "       'Defense & space', 'Business supplies & equipment', 'Nft',\n",
       "       'Oil & energy', 'Company-as-a-service', 'Textiles',\n",
       "       'Professional training & coaching', 'Maritime',\n",
       "       'Housing marketplace', 'Furniture rental', 'Telecommunications',\n",
       "       'Equity management', 'Community', 'Higher education',\n",
       "       'Mechanical or industrial engineering', 'D2c jewellery',\n",
       "       'Sales and distribution', 'Translation & localization',\n",
       "       'Investment banking', 'Foootwear', 'Legal services',\n",
       "       'Arts & crafts', 'Investment management', 'Management consulting',\n",
       "       'B2b startup', 'Design', 'B2b travel', 'Product studio',\n",
       "       'Aviation & aerospace', 'Staffing & recruiting'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first sentence of every list\n",
    "merged_df['industry']=merged_df['industry'].str.split(\",\").str[0].astype('str')\n",
    "merged_df['industry'].unique()\n",
    "# merged_df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "IT & Technology               1070\n",
       "Online Retail                  879\n",
       "Healthcare & Life Sciences     195\n",
       "Financial Services             165\n",
       "Consumer Goods                 127\n",
       "Media & Entertainment           97\n",
       "Transportation & Logistics      83\n",
       "Manufacturing                   76\n",
       "Business Services               70\n",
       "Sports                          34\n",
       "Others                          30\n",
       "Agriculture                     15\n",
       "Travel & Tourism                15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# Mapping the industries to sectors using regular expre\n",
    "def map_sector(industry):\n",
    "    if re.search(r'\\b(3D Printing|Analytics|.*Tech.*|Android|Apps|Artificial Intelligence|Battery|Big Data|Blockchain|CleanTech|Cloud Computing|Cloud Infrastructure|Collaboration|Communities|Computer|Consumer Applications|Embedded Systems|Energy|Enterprise Resource Planning \\(ERP\\)|Enterprise Software|File Sharing|Information Services|Information Technology|Internet|Internet of Things|Mobile|Nanotechnology|Renewable Energy|Search Engine|Smart Cities|Software)\\b', industry, re.IGNORECASE):\n",
    "        return 'IT & Technology'\n",
    "    elif re.search(r'\\b(Accounting|B2B|Business Development|Business Intelligence|Business Travel|Career Planning|Consulting|Creative Agency|Crowdsourcing|Customer Service|Environmental Consulting|Facilities Support Services|Government|Human Resources|Market Research)\\b', industry, re.IGNORECASE):\n",
    "        return 'Business Services'\n",
    "    elif re.search(r'\\b(Advertising|Audio|Brand Marketing|Broadcasting|Classifieds|Digital Entertainment|Digital Marketing|Digital Media|Gaming|Marketing|Media and Entertainment|Music|Music Streaming|News|Online Games|Online Portals|Reading Apps|Social Media)\\b', industry, re.IGNORECASE):\n",
    "        return 'Media & Entertainment'   \n",
    "    elif re.search(r'\\b(Aerospace|Automotive|Autonomous Vehicles|Industrial|Industrial Automation|Packaging Services)\\b', industry, re.IGNORECASE):\n",
    "        return 'Manufacturing'\n",
    "    elif re.search(r'\\b(AgTech|Agriculture|Farming)\\b', industry, re.IGNORECASE):\n",
    "        return 'Agriculture'\n",
    "    elif re.search(r'\\b(Air Transportation|Delivery|Delivery Service|Electric Vehicle|Last Mile Transportation|Logistics|Transportation|Transportation)\\b', industry, re.IGNORECASE):\n",
    "        return 'Transportation & Logistics'\n",
    "    elif re.search(r'\\b(Hel.*|Hea.*|Hosp.*|Vet.*|Pharma.*|Alternative Medicine|Biopharma|Biotechnology|Dental|Dietary Supplements|Child Care|Health Care|Health Diagnostics|Hospital|Medical|Medical Device|Veterinary|Wellness|Healthcare)\\b', industry, re.IGNORECASE):\n",
    "        return 'Healthcare & Life Sciences'\n",
    "    elif re.search(r'\\b(Fin.*|Banking|Consumer Lending|Credit|Credit Cards|Crowdfunding|Cryptocurrency|FinTech|Finance|Financial Services|Fraud Detection|Funding Platform|Health Insurance|Insurance|Mobile Payments|Trading Platform|Wealth Management)\\b', industry, re.IGNORECASE):\n",
    "        return 'Financial Services'\n",
    "    elif re.search(r'\\b(Basketball|Fantasy Sports|Fitness|Sports|eSports)\\b', industry, re.IGNORECASE):\n",
    "        return 'Sports'\n",
    "    elif re.search(r'\\b(Beauty|Children|Consumer|Consumer Electronics|Cooking|Cosmetics|Eyewear|Fashion|Food Processing|Food and Beverage|Home Decor)\\b', industry, re.IGNORECASE):\n",
    "        return  'Consumer Goods'\n",
    "    elif re.search(r'\\b(Catering|.*travel.*|Events|Hospitality|Tourism|Travel|Wedding)\\b', industry, re.IGNORECASE):\n",
    "        return 'Travel & Tourism' \n",
    "    elif re.search(r'\\b(E-Commerce|E-Commerce Platforms|Marketplace|Retail|.*commerce.*|)\\b', industry, re.IGNORECASE):\n",
    "        return 'Online Retail' \n",
    "    elif re.search(r'\\b(Continuing Education|.*Edu.*|learn|academy|Professional Training & Coaching|tutor|stem|Higher Educatio|E-Learning|EdTech|edttech|Preschool Daycare|school|Education|edutech|Teaching|Training)\\b', industry, re.IGNORECASE):\n",
    "        return 'Education'\n",
    "    elif re.search(r'\\b(Commercial|Commercial Real Estate|Rental||Housing Marketplace|Furniture Rental|Real estate|Housing|Rental|Furniture|Rental space|Proptech)\\b', industry, re.IGNORECASE):\n",
    "        return 'Real Estate'\n",
    "    elif re.search(r'\\b(Clean Energy|.*nergy.*|EV|Solar.*|Ev startup|Electricity|Wl & rac protection)\\b', industry, re.IGNORECASE):\n",
    "        return 'Energy'\n",
    "    else:\n",
    "        return 'Others'\n",
    "    \n",
    "# # Apply the function to the Industry column\n",
    "merged_df['industry'] = merged_df['industry'].apply(map_sector)\n",
    "\n",
    "# # Display the DataFrame to verify the changes\n",
    "merged_df['industry'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company_name</th>\n",
       "      <th>industry</th>\n",
       "      <th>funding_stage</th>\n",
       "      <th>Amount_in_usd</th>\n",
       "      <th>about_company</th>\n",
       "      <th>year_funded</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Founders</th>\n",
       "      <th>Investor</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>58</td>\n",
       "      <td>MissMalini Entertainment</td>\n",
       "      <td>Others</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1518400.0</td>\n",
       "      <td>MissMalini Entertainment is a multi-platform n...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>Jagaran Microfin</td>\n",
       "      <td>Others</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>8030000.0</td>\n",
       "      <td>Jagaran Microfin is a Microfinance institution...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>121</td>\n",
       "      <td>FLEECA</td>\n",
       "      <td>Others</td>\n",
       "      <td>Seed</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>FLEECA is a Tyre Care Provider company.</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>WheelsEMI</td>\n",
       "      <td>Others</td>\n",
       "      <td>Series B</td>\n",
       "      <td>14000000.0</td>\n",
       "      <td>WheelsEMI is the brand name of NBFC, WheelsEMI...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>Fric Bergen</td>\n",
       "      <td>Others</td>\n",
       "      <td>Venture - Series Unknown</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>Fric Bergen is a leader in the specialty food ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alwar</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index              company_name industry             funding_stage  \\\n",
       "58      58  MissMalini Entertainment   Others                      Seed   \n",
       "105    105          Jagaran Microfin   Others            Debt Financing   \n",
       "121    121                    FLEECA   Others                      Seed   \n",
       "146    146                 WheelsEMI   Others                  Series B   \n",
       "153    153               Fric Bergen   Others  Venture - Series Unknown   \n",
       "\n",
       "     Amount_in_usd                                      about_company  \\\n",
       "58       1518400.0  MissMalini Entertainment is a multi-platform n...   \n",
       "105      8030000.0  Jagaran Microfin is a Microfinance institution...   \n",
       "121      3000000.0            FLEECA is a Tyre Care Provider company.   \n",
       "146     14000000.0  WheelsEMI is the brand name of NBFC, WheelsEMI...   \n",
       "153      3000000.0  Fric Bergen is a leader in the specialty food ...   \n",
       "\n",
       "     year_funded  Founded Founders Investor     city        state country  \n",
       "58          2018      NaN      NaN      NaN   Mumbai  Maharashtra   India  \n",
       "105         2018      NaN      NaN      NaN  Kolkata  West Bengal   India  \n",
       "121         2018      NaN      NaN      NaN   Jaipur    Rajasthan   India  \n",
       "146         2018      NaN      NaN      NaN     Pune  Maharashtra   India  \n",
       "153         2018      NaN      NaN      NaN    Alwar    Rajasthan   India  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only the rows with the \"Others\" industry\n",
    "others_ind = merged_df[merged_df[\"industry\"] == \"Others\" ]\n",
    "others_ind.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58     MissMalini Entertainment is a multi-platform n...\n",
       "105    Jagaran Microfin is a Microfinance institution...\n",
       "121              FLEECA is a Tyre Care Provider company.\n",
       "146    WheelsEMI is the brand name of NBFC, WheelsEMI...\n",
       "153    Fric Bergen is a leader in the specialty food ...\n",
       "174    Deftouch is a mobile game development company ...\n",
       "181    Corefactors is a leading campaign management, ...\n",
       "210    Cell Propulsion is an electric mobility startu...\n",
       "230                      FInd your Customized Home here.\n",
       "235    dishq leverages food science and machine learn...\n",
       "238    Trell is a location based network which helps ...\n",
       "242          New Apartments, Flats for Sale in Bangalore\n",
       "243    It is a fabless semiconductor company focused ...\n",
       "247    SaffronStays connects travellers to India's In...\n",
       "251    Inner Being Wellness manufactures beauty, well...\n",
       "257    SEO, PPC, Search Engine Marketing, Social Medi...\n",
       "258                             Digital Marketing Agency\n",
       "259    Scale Labs is a cross border e-commerce soluti...\n",
       "294    Transforming the way businesses deliver. Work-...\n",
       "325    Toffee is a bite size, micro-event & contextua...\n",
       "326                    Online wealth management platform\n",
       "346    Finwego partners with Small and Medium Busines...\n",
       "397    Cred is a platform to celebrate and reward the...\n",
       "456    Origo Commodities, a complete post-harvest man...\n",
       "471              Sequretek is a cyber security start-up.\n",
       "472    Avenues Payments is an IT solutions provider f...\n",
       "475    Planet11 is backed by SK Planet, which is a pa...\n",
       "477         Iba Halal Care is a cosmetics brand company.\n",
       "479    Togedr is an activity discovery & booking plat...\n",
       "509                                              Edutech\n",
       "Name: about_company, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the descriptions of the companies with the others categories\n",
    "others_ind[\"about_company\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "IT & Technology               1075\n",
       "Online Retail                  879\n",
       "Healthcare & Life Sciences     195\n",
       "Financial Services             170\n",
       "Consumer Goods                 132\n",
       "Media & Entertainment           98\n",
       "Transportation & Logistics      84\n",
       "Manufacturing                   76\n",
       "Business Services               74\n",
       "Sports                          34\n",
       "Travel & Tourism                16\n",
       "Agriculture                     15\n",
       "Others                           7\n",
       "Education                        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary to contain the keywords in the what_it_does column\n",
    "keywords = {\n",
    "    'entertainment': 'Media & Entertainment',\n",
    "    'microfinance': 'Financial Services',\n",
    "    'tyre care': 'Consumer Goods',\n",
    "    'nbfc': 'Financial Services',\n",
    "    'specialty food': 'Consumer Goods',\n",
    "    'mobile game development': 'IT & Technology',\n",
    "    'campaign management': 'Business Services',\n",
    "    'electric mobility startup': 'Transportation & Logistics',\n",
    "    'food science': 'Consumer Goods',\n",
    "    'machine learning': 'IT & Technology',\n",
    "    'location based network': 'IT & Technology',\n",
    "    'real estate': 'Real Estate',\n",
    "    'semiconductor company': 'IT & Technology',\n",
    "    'travellers accommodation': 'Travel & Tourism',\n",
    "    'beauty, wellness': 'Consumer Goods',\n",
    "    'search engine marketing': 'IT & Technology',\n",
    "    'digital marketing agency': 'Business Services',\n",
    "    'cross border e-commerce solutions': 'Business Services',\n",
    "    'wealth management platform': 'Financial Services',\n",
    "    'micro-event & contextual marketing': 'Business Services',\n",
    "    'partners with small and medium businesses': 'Financial Services',\n",
    "    'celebrate and reward': 'Financial Services',\n",
    "    'post-harvest management': 'Business Services',\n",
    "    'cyber security': 'IT & Technology',\n",
    "    'cosmetics brand': 'Consumer Goods',\n",
    "    'activity discovery & booking platform': 'Travel & Tourism',\n",
    "    'edutech': 'Education'\n",
    "}\n",
    "\n",
    "# Function to assign sector based on description\n",
    "def assign_sector(about_company):\n",
    "    for keyword,industry in keywords.items():\n",
    "        if keyword in about_company.lower():\n",
    "            return industry\n",
    "    return \"Others\" #Keep Others if no keyword matches\n",
    "\n",
    "# Update sectors for entries currently labeled as \"Others\"\n",
    "merged_df.loc[merged_df['industry'] == 'Others', 'industry'] = merged_df.loc[merged_df['industry'] == 'Others', 'about_company'].apply(assign_sector)\n",
    "merged_df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "merged_df['industry'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the funding_stage cplumn\n",
    "\n",
    "Startups start with pre-seed, progress through seed, Series A, Series B, etc., securing resources for development and strategies. Additional rounds like Series C or D may follow. External funding at each stage fuels growth toward the venture's full potential.\n",
    "\n",
    "link: https://www.startupindia.gov.in/content/sih/en/funding.html\n",
    "\n",
    "\n",
    "age of Funding\tStage mapping\n",
    "Ideation\tPre-Seed funding\n",
    "Validation\tMid series, Seed Round & Series A, Seed funding\n",
    "Early Traction\tSeries A\n",
    "Scaling\tSeries B, Series C, Series D, Series E, Series F, Series G, Series H, Series I\n",
    "Exit Option\tPost-IPO Debt, Post-IPO Equity, Secondary Market\n",
    "| Other | Private Equity, Corporate Round, Undisclosed, Non-equity Assistance, Debt, Bridge, Edge\n",
    "\n",
    "\n",
    "Stages\tDescription\n",
    "Others\tMiscellaneous phases or unique development activities.\n",
    "Early Traction\tGaining initial traction, attracting early adopters, and refining based on feedback.\n",
    "Validation\tValidating the business model, product-market fit, and scalability through research and feedback.\n",
    "Ideation\tBrainstorming and developing business concepts, defining value propositions, and outlining plans.\n",
    "Scaling\tExpanding operations, customer base, and market reach for rapid growth.\n",
    "Exit Option\tConsidering exit strategies such as mergers, acquisitions, or IPOs.\n",
    "\n",
    "\n",
    "After Research on the stages of startup from the , we decided to regroup the stages into these categories based on the stage of a start-up\n",
    "\n",
    "Ideation - Ideation is a stage where the initial business plan has been formed and the start-up is growing with little or no capital. The business relies heavily on savings, family and friends and grant money.\n",
    "\n",
    "Validation - At this stage, the startup needs to prove the potential rate of success with the business idea.It needs to conduct field trials, test products on customers and build a small formal team. Funding usually comes from government loan schemes (to encourage entrepreneurs) , angel investors (individuals who invest their money in return for equity), incubators (specific goal of assisting and launching startups) or crowdfunding (conrtibution of amount from a large number of people via platforms).\n",
    "\n",
    "Early Traction - Startup services have been launched into the market. KPIs, customer churn, revenue and geographic expansion are a priority at this stage. Sources of funding include venture capital funds, bank debts, and venture debt funds\n",
    "\n",
    "Scaling - In this stage, there is an increase in revenue and market growth.It includes Series B,C,D and E. Sources of funding include venture capitals especially when the startup has gained major market attention. Some private equity or investment funds may provide funds for startups with consistent growth record.\n",
    "\n",
    "Exit Option - In this stage, the investors may decide to merge the company with another, list the companies in the stock market(for those with impressive record of profits), sell shares to other private equity firms or the founders may even buy back their shares in order to gain back control of the company.\n",
    "\n",
    "Others for these stages: Private Equity, Corporate Round, Non-equity Assistance, Debt, Bridge, Edge\n",
    "\n",
    "Undisclosed for all values of \"Undisclosed\",None and Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Seed', 'Series A', 'Angel', 'Series B', 'Pre-Seed',\n",
       "       'Private Equity', 'Venture - Series Unknown', 'Grant',\n",
       "       'Debt Financing', 'Post-IPO Debt', 'Series H', 'Series C',\n",
       "       'Series E', 'Corporate Round', 'Undisclosed',\n",
       "       'https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593',\n",
       "       'Series D', 'Secondary Market', 'Post-IPO Equity',\n",
       "       'Non-equity Assistance', 'Funding Round', nan, 'Fresh funding',\n",
       "       'Pre series A', 'Series G', 'Post series A', 'Seed funding',\n",
       "       'Seed fund', 'Series F', 'Series B+', 'Seed round', 'Pre-series A',\n",
       "       None, 'Pre-seed', 'Pre-series', 'Debt', 'Pre-series C',\n",
       "       'Pre-series B', 'Bridge', 'Series B2', 'Pre- series A', 'Edge',\n",
       "       'Pre-Series B', 'Seed A', 'Series A-1', 'Seed Funding',\n",
       "       'Pre-seed Round', 'Seed Round & Series A', 'Pre Series A',\n",
       "       'Pre seed Round', 'Angel Round', 'Pre series A1', 'Series E2',\n",
       "       'Seed Round', 'Bridge Round', 'Pre seed round', 'Pre series B',\n",
       "       'Pre series C', 'Seed Investment', 'Series D1', 'Mid series',\n",
       "       'Series C, D', 'undisclosed', 'Seed+', 'Series F2', 'Series A+',\n",
       "       'Series B3', 'PE', 'Series F1', 'Pre-series A1', 'None',\n",
       "       'Early seed', 'Seies A', 'Series A2', 'Series I'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view unique values\n",
    "merged_df['funding_stage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Early Traction', 'Scaling', 'Validation', 'Exit Options',\n",
       "       'Unknown'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re                      \n",
    "\n",
    "# Define the mapping using a list of dictionaries\n",
    "def map_stage(funding_stage):\n",
    "    if pd.isna(funding_stage) or funding_stage in ['Undisclosed', 'undisclosed', 'None', 'https://docs.google.com/spreadsheets/d/1x9ziNeaz6auNChIHnMI8U6kS7knTr3byy_YBGfQaoUA/edit#gid=1861303593']:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    if re.search(r'\\b(Bootstrapping|Self-funding)\\b', funding_stage, re.IGNORECASE):\n",
    "        return 'Ideation'\n",
    "    elif re.search(r'\\b(Pre-Seed|Angel|Grant|Non-equity Assistance|Early Seed)\\b', funding_stage, re.IGNORECASE): \n",
    "        return 'Validation'\n",
    "    elif re.search(r'\\b(Seed|Seed Funding|Seed Fund|Seed Round|Seed Investment|Pre Series A|Pre-Seed Round|Pre Series A1)\\b', funding_stage , re.IGNORECASE):\n",
    "        return 'Early Traction'\n",
    "    elif re.search(r'\\b(Series [A-I]|Private Equity|Venture - Series Unknown|Corporate Round|Secondary Market|Fresh Funding|Post Series A|Series B\\+|Pre-Series A1|Series A\\+|Series B3|PE|Series F1|Series A2|Mid Series|Series C, D|Series E2|Series D1|Series F2|Series B2|Series A-1|Pre-Series B|Pre-Series C)\\b', funding_stage, re.IGNORECASE):\n",
    "        return 'Scaling'\n",
    "    elif re.search(r'\\b(Debt Financing|Post-IPO Debt|Post-IPO Equity|Bridge|Bridge Round|Debt|Funding Round|Edge)\\b', funding_stage, re.IGNORECASE):\n",
    "        return 'Exit Options'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "    \n",
    "# Apply the function to the 'funding_stage' column\n",
    "merged_df['funding_stage'] = merged_df['funding_stage'].apply(lambda x: map_stage(x)).astype(str)\n",
    "\n",
    "# Print the DataFrame to check the results\n",
    "merged_df['funding_stage'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "\n",
    "merged_df['funding_stage'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning the investor column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Sixth Sense Ventures', 'General Atlantic', ...,\n",
       "       'Owl Ventures', 'Winter Capital, ETS, Man Capital',\n",
       "       '3one4 Capital, Kalaari Capital'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merged_df['Investor'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Investor\n",
       "Inflection Point Ventures                                                35\n",
       "Venture Catalysts                                                        32\n",
       "Mumbai Angels Network                                                    17\n",
       "Angel investors                                                          15\n",
       "Undisclosed                                                              13\n",
       "                                                                         ..\n",
       "Bytedance, Falcon Edge, Goldman Sachs, Advent Management                  1\n",
       "INSEAD Angels, IIT Kanpur Angels, Sixth Sense Ventures, Saahil Bhatia     1\n",
       "Sukhbir Singh, Rakhee Singal                                              1\n",
       "Angel Network                                                             1\n",
       "3one4 Capital, Kalaari Capital                                            1\n",
       "Name: count, Length: 1771, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Cleaning the investor cokumn\n",
    "\n",
    "merged_df['Investor'].value_counts()\n",
    "\n",
    "#check for nulls\n",
    "# merged_df['Investor'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Investor'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all the Nulls with undisclosed\n",
    "merged_df[\"Investor\"].fillna(\"Undisclosed\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Investor'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cleaning the founded column\n",
    "\n",
    "We will be cleaning the missing values by fill them using interpolate method which is suitable for time series data\n",
    "\n",
    "We will also be converting the data type from float to datetime for purpose of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 2014., 2004., 2013., 2010., 2018., 2019., 2017., 2011.,\n",
       "       2015., 2016., 2012., 2008., 2020., 1998., 2007., 1982., 2009.,\n",
       "       1995., 2006., 1978., 1999., 1994., 2005., 1973., 2002., 2001.,\n",
       "       2021., 1993., 1989., 2000., 2003., 1991., 1984., 1963.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['Founded'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Remove unwanted characters\n",
    "merged_df['Founded'] = merged_df['Founded'].replace(['...', np.nan], np.NaN)\n",
    "\n",
    "merged_df['Founded'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the nulls\n",
    "merged_df[\"Founded\"].fillna(method ='bfill',inplace = True)\n",
    "\n",
    "merged_df['Founded'].isna().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the company_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TheCollegeFever', 'Happy Cow Dairy', 'MyLoanCare', ...,\n",
       "       'Cogos Technologies', 'Vahdam', 'WeRize'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['company_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['company_name'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the founders column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted characters\n",
    "merged_df['Founders'] = merged_df['Founders'].replace(['...', np.nan], np.NaN)\n",
    "\n",
    "# Check the number of NaN values in the 'founders' column\n",
    "merged_df['Founders'].isna().sum()\n",
    "\n",
    "\n",
    "#fill the nulls with unknown\n",
    "merged_df['Founders'].fillna('unknown', inplace = True)\n",
    "\n",
    "merged_df['Founders'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned data to csv file\n",
    "merged_df.to_csv('indian_ecosystem_merged_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <td>2856.0</td>\n",
       "      <td>4.982829e+02</td>\n",
       "      <td>3.334439e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>453.5</td>\n",
       "      <td>774.25</td>\n",
       "      <td>1.208000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount_in_usd</th>\n",
       "      <td>2856.0</td>\n",
       "      <td>9.849275e+07</td>\n",
       "      <td>3.097961e+09</td>\n",
       "      <td>876.0</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>8000000.00</td>\n",
       "      <td>1.500000e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_funded</th>\n",
       "      <td>2856.0</td>\n",
       "      <td>2.020018e+03</td>\n",
       "      <td>1.087759e+00</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2021.00</td>\n",
       "      <td>2.021000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Founded</th>\n",
       "      <td>2856.0</td>\n",
       "      <td>2.015596e+03</td>\n",
       "      <td>3.963923e+00</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2018.00</td>\n",
       "      <td>2.021000e+03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count          mean           std     min        25%  \\\n",
       "index          2856.0  4.982829e+02  3.334439e+02     0.0      210.0   \n",
       "Amount_in_usd  2856.0  9.849275e+07  3.097961e+09   876.0  1000000.0   \n",
       "year_funded    2856.0  2.020018e+03  1.087759e+00  2018.0     2020.0   \n",
       "Founded        2856.0  2.015596e+03  3.963923e+00  1963.0     2014.0   \n",
       "\n",
       "                     50%         75%           max  \n",
       "index              453.5      774.25  1.208000e+03  \n",
       "Amount_in_usd  3000000.0  8000000.00  1.500000e+11  \n",
       "year_funded       2020.0     2021.00  2.021000e+03  \n",
       "Founded           2016.0     2018.00  2.021000e+03  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Amount_in_usd' column shows a high degree of variability with significant outliers, as indicated by the large standard deviation and the maximum value.\n",
    "The 'year_funded' column shows that most funding happened around the years 2020 and 2021, with minimal variation.\n",
    "The 'Founded' column indicates that most companies were founded in recent years, with a few outliers going back several decades.\n",
    "The presence of NaN values in the 'Founded' column means some founding year data is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index              0\n",
       "company_name       0\n",
       "industry           0\n",
       "funding_stage      0\n",
       "Amount_in_usd      0\n",
       "about_company      0\n",
       "year_funded        0\n",
       "Founded            0\n",
       "Founders           0\n",
       "Investor           0\n",
       "city               0\n",
       "state            237\n",
       "country          194\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypothesis Testing\n",
    "Null Hypothesis(Ho): There is no significant difference in the amount of funding received by Indian startups from 2018 to 2021.\n",
    "Alternative Hypothesis(Ha): There is significant difference  in the amount of funding received by Indian start-ups from 2018 to 2021.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANOVA results for industry:\n",
      "                    sum_sq      df         F    PR(>F)\n",
      "C(industry)  9.172502e+18    13.0  0.073208  0.999997\n",
      "Residual     2.739130e+22  2842.0       NaN       NaN \n",
      "\n",
      "ANOVA results for funding_stage:\n",
      "                         sum_sq      df         F    PR(>F)\n",
      "C(funding_stage)  2.931525e+20     4.0  7.708045  0.000004\n",
      "Residual          2.710732e+22  2851.0       NaN       NaN \n",
      "\n",
      "ANOVA results for state:\n",
      "                 sum_sq      df         F    PR(>F)\n",
      "C(state)  6.319472e+19    20.0  0.300403  0.998868\n",
      "Residual  2.732657e+22  2598.0       NaN       NaN \n",
      "\n",
      "ANOVA results for year_funded:\n",
      "                       sum_sq      df         F    PR(>F)\n",
      "C(year_funded)  7.592413e+18     3.0  0.263494  0.851735\n",
      "Residual        2.739288e+22  2852.0       NaN       NaN \n",
      "\n",
      "ANOVA results for Founded:\n",
      "                   sum_sq      df        F    PR(>F)\n",
      "C(Founded)  5.545234e+20    33.0  1.76638  0.004568\n",
      "Residual    2.684595e+22  2822.0      NaN       NaN \n",
      "\n",
      "ANOVA results for Founders:\n",
      "                    sum_sq      df         F        PR(>F)\n",
      "C(Founders)  2.374881e+22  1979.0  2.878791  6.972026e-65\n",
      "Residual     3.651659e+21   876.0       NaN           NaN \n",
      "\n",
      "ANOVA results for Investor:\n",
      "                    sum_sq      df         F  PR(>F)\n",
      "C(Investor)  4.936712e+21  1770.0  0.134714     1.0\n",
      "Residual     2.246376e+22  1085.0       NaN     NaN \n",
      "\n",
      "ANOVA results for city:\n",
      "                 sum_sq      df         F  PR(>F)\n",
      "C(city)   8.955924e+19    91.0  0.099603     1.0\n",
      "Residual  2.731091e+22  2764.0       NaN     NaN \n",
      "\n",
      "Significant factors (p < 0.05): ['funding_stage', 'Founded', 'Founders']\n",
      "Fail to reject the null hypothesis: There is no significant difference in the  funding amounts across the years.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "#define threshhold\n",
    "threshold = 0.05\n",
    "\n",
    "anova_results = {}\n",
    "significant_factors = []\n",
    "\n",
    "# List of categorical columns\n",
    "categorical_cols = ['industry', 'funding_stage', 'state', 'year_funded', 'Founded', 'Founders', 'Investor', 'city']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    model = ols(f'Amount_in_usd ~ C({col})', data = merged_df).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    anova_results[col] = anova_table\n",
    "    \n",
    "    # Check if the p-value is below the threshold of 0.05\n",
    "    if anova_table[\"PR(>F)\"][0] < 0.05:\n",
    "        significant_factors.append(col)\n",
    "\n",
    "# Display the ANOVA results\n",
    "for col, result in anova_results.items():\n",
    "    print(f\"ANOVA results for {col}:\\n\", result, \"\\n\")\n",
    "\n",
    "# Display significant factors\n",
    "print(\"Significant factors (p < 0.05):\", significant_factors)\n",
    "\n",
    "# Interpret the results\n",
    "p_value = anova_table['PR(>F)'][0]\n",
    "if p_value < threshold:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference in the average funding amounts across different sectors.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference in the  funding amounts across the years.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Hypothesis\n",
    "# import statsmodels.api as sm\n",
    "# from statsmodels.formula.api import ols\n",
    "\n",
    "# #define threshhold\n",
    "# threshold = 0.05\n",
    "\n",
    "# #perform ANoVA on each col\n",
    "# col = ['industry', 'funding_stage','state, 'year_funded', 'Founded', 'Founders','Investor', 'city']\n",
    "# p_values = {}\n",
    "\n",
    "# for column in col:\n",
    "#     model = ols('Amount_in_usd ~ {}'.format(column), data = merged_df).fit()\n",
    "#     anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "#     p_value = anova_table['PR(>F)'][0]\n",
    "#     p_value_decimal = round(float(p_value),2)\n",
    "#     print(anova_table)\n",
    "#    # print(p_value_decimal)\n",
    "#     p_values[column] = p_value_decimal\n",
    "\n",
    "\n",
    "#     #compare p-values\n",
    "#     significant_factors = [column for column, p_value in p_values.items() if p_value < threshold]\n",
    "#     print(\"significant factors with p_values below {}: {}\".format(threshold, significant_factors))\n",
    "\n",
    "\n",
    "# # # Function to perform ANOVA and print results\n",
    "# # def perform_anova(data, target_col, feature_col):\n",
    "# #     formula = f'{target_col} ~ C({feature_col})'\n",
    "# #     model = ols(formula, data=data).fit()\n",
    "# #     anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "# #     print(f'ANOVA results for {feature_col}:\\n', anova_table, '\\n')\n",
    "\n",
    "# Perform ANOVA for each column\n",
    "# for col in columns:\n",
    "    # perform_anova(merged_df, 'amount_in_usd', col)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #compare p_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytical Questions\n",
    "1.\tWhat are the trends in the total amount of funding received by Indian startups from 2018 to 2021?\n",
    "2.\tWhich sectors have attracted the most investment during each year, and how have these trends evolved over the four years?\n",
    "3.\tWho are the highest investors, Total Fund invested and sector? \n",
    "4.\tAt which stage are Indian-Start-ups funded the most?\n",
    "5. How is startup funding distributed across different sectors and regions. Highest and lowest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trends in amount recieved over the years\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter data for the years 2018 to 2021\n",
    "df_filtered = df[(df['year_funded'] >= 2018) & (df['year_funded'] <= 2021)]\n",
    "\n",
    "# Aggregate the total funding amount for each year\n",
    "funding_trends = df_filtered.groupby('year_funded')['amount_in_usd'].sum().reset_index()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(funding_trends['year_funded'], funding_trends['amount_in_usd'], marker='o', linestyle='-', color='b')\n",
    "plt.title('Trends in Total Funding Amount for Indian Startups (2018-2021)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Total Funding Amount (in USD)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
